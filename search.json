[{"title":"转载 - 零基础入门深度学习(3) - 神经网络和反向传播算法","url":"%2F2019%2F05%2F08%2Fdeeplearning-quickstart-3%2F","content":"\n![](/static/upload-images.jianshu.io/upload_images/2256672-06627c71f0d8c0dc.jpg)\n\n> 无论即将到来的是大数据时代还是人工智能时代，亦或是传统行业使用人工智能在云上处理大数据的时代，作为一个有理想有追求的程序员，\n不懂深度学习（Deep Learning）这个超热的技术，会不会感觉马上就out了？现在救命稻草来了，《零基础入门深度学习》\n系列文章旨在讲帮助爱编程的你从零基础达到入门级水平。零基础意味着你不需要太多的数学知识，只要会写程序就行了，没错，\n这是专门为程序员写的文章。虽然文中会有很多公式你也许看不懂，但同时也会有更多的代码，程序员的你一定能看懂的\n（我周围是一群狂热的Clean Code程序员，所以我写的代码也不会很差）。\n\n## 往期回顾\n\n在上一篇文章中，我们已经掌握了机器学习的基本套路，对模型、目标函数、优化算法这些概念有了一定程度的理解，而且已经会训练单个的感知器或者线性单元了。在这篇文章中，我们将把这些单独的单元按照一定的规则相互连接在一起形成 **神经网络** ，从而奇迹般的获得了强大的学习能力。我们还将介绍这种网络的训练算法： **反向传播算法** 。最后，我们依然用代码实现一个神经网络。如果您能坚持到本文的结尾，将会看到我们用自己实现的神经网络去识别手写数字。现在请做好准备，您即将双手触及到深度学习的大门。\n\n## 神经元\n\n神经元和感知器本质上是一样的，只不过我们说感知器的时候，它的激活函数是 **阶跃函数** ；而当我们说神经元时，激活函数往往选择为sigmoid函数或tanh函数。如下图所示：\n\n<!-- more -->\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-49f06e2e9d3eb29f.gif)\n\n计算一个神经元的输出的方法和计算一个感知器的输出是一样的。假设神经元的输入是向量 $\\vec{x}$ ，权重向量是 $\\vec{w}$ (偏置项是 $w_0$ )，激活函数是sigmoid函数，则其输出 $y$ ：\n\n$$\ny = sigmoid(\\vec{w}^T \\cdot \\vec{x}) \\pod{式1}\n$$\n\nsigmoid函数的定义如下：\n\n$$\nsigmoid(x) = \\frac{1}{1 + e^{-x}}\n$$\n\n将其带入前面的式子，得到\n\n$$\ny = \\frac{1}{1 + e^{- \\vec{w}^T \\cdot \\vec{x}}}\n$$\n\nsigmoid函数是一个非线性函数，值域是(0,1)。函数图像如下图所示\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-e7e64f57dc6b1c64.jpg)\n\nsigmoid函数的导数是：\n\n$$\n\\begin{aligned}\n    &\\text{令} y = sigmoid(x) &\\pod{1} \\\\\n    &\\text{则} y' = y(y -1) &\\pod{2}\n\\end{aligned}\n$$\n\n可以看到，sigmoid函数的导数非常有趣，它可以用sigmoid函数自身来表示。这样，一旦计算出sigmoid函数的值，计算它的导数的值就非常方便。\n\n## 神经网络是啥\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-92111b104ce0d571.jpeg)\n\n神经网络其实就是按照 **一定规则** 连接起来的多个 **神经元** 。上图展示了一个 **全连接(full connected, FC)** 神经网络，通过观察上面的图，我们可以发现它的规则包括：\n\n- 神经元按照层来布局。最左边的层叫做 **输入层** ，负责接收输入数据；最右边的层叫 **输出层** ，我们可以从这层获取神经网络输出数据。输入层和输出层之间的层叫做 **隐藏层** ，因为它们对于外部来说是不可见的。\n\n- 同一层的神经元之间没有连接。\n\n- 第N层的每个神经元和第N-1层的 **所有** 神经元相连(这就是full connected的含义)，第N-1层神经元的输出就是第N层神经元的输入。\n\n- 每个连接都有一个 **权值** 。\n\n上面这些规则定义了全连接神经网络的结构。事实上还存在很多其它结构的神经网络，比如卷积神经网络(CNN)、循环神经网络(RNN)，他们都具有不同的连接规则。\n\n## 计算神经网络的输出\n\n神经网络实际上就是一个输入向量 $\\vec{x}$ 到输出向量 $\\vec{y}$ 的函数，即：\n\n$$\n\\vec{y} = f_{network}(\\vec{x})\n$$\n\n根据输入计算神经网络的输出，需要首先将输入向量 $\\vec{x}$ 的每个元素 $x_i$ 的值赋给神经网络的输入层的对应神经元，然后根据 **式1** 依次向前计算每一层的每个神经元的值，直到最后一层输出层的所有神经元的值计算完毕。最后，将输出层每个神经元的值串在一起就得到了输出向量 $\\vec{y}$ 。\n\n接下来举一个例子来说明这个过程，我们先给神经网络的每个单元写上编号。\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-bfbb364740f898d1.png)\n\n如上图，输入层有三个节点，我们将其依次编号为1、2、3；隐藏层的4个节点，编号依次为4、5、6、7；最后输出层的两个节点编号为8、9。因为我们这个神经网络是 **全连接** 网络，所以可以看到每个节点都和 **上一层的所有节点** 有连接。比如，我们可以看到隐藏层的节点4，它和输入层的三个节点1、2、3之间都有连接，其连接上的权重分别为 $w_{41}, w_{42}, w_{43}$ 。那么，我们怎样计算节点4的输出值 $a_4$ 呢？\n\n为了计算节点4的输出值，我们必须先得到其所有上游节点（也就是节点1、2、3）的输出值。节点1、2、3是 **输入层** 的节点，所以，他们的输出值就是输入向量 $\\vec{x}$ 本身。按照上图画出的对应关系，可以看到节点1、2、3的输出值分别是 $x_1, x_2, x_3$ 。我们要求 **输入向量的维度和输入层神经元个数相同** ，而输入向量的某个元素对应到哪个输入节点是可以自由决定的，你偏非要把 $x_1$ 赋值给节点2也是完全没有问题的，但这样除了把自己弄晕之外，并没有什么价值。\n\n一旦我们有了节点1、2、3的输出值，我们就可以根据 **式1** 计算节点4的输出值 $a_4$ ：\n\n$$\n\\begin{aligned}\n    a_4 &= sigmoid(\\vec{w}^T \\cdot \\vec{x}) &\\pod{3} \\\\\n        &= sigmoid(w_{41} x_1 + w_{42} x_2 + w_{43} x_3 + w_{4b}) &\\pod{4}\n\\end{aligned}\n$$\n\n上式的 $w_{4b}$ 是节点4的 **偏置项** ，图中没有画出来。而 $w_{41}, w_{42}, w_{43}$ 分别为节点1、2、3到节点4连接的权重，在给权重 $w_{ji}$ 编号时，我们把目标节点的编号 $j$ 放在前面，把源节点的编号 $i$ 放在后面。\n\n同样，我们可以继续计算出节点5、6、7的输出值 $a_5, a_6, a_7$ 。这样，隐藏层的4个节点的输出值就计算完成了，我们就可以接着计算输出层的节点8的输出值 $y_1$ ：\n\n$$\n\\begin{aligned}\n    y_1 &= sigmoid(\\vec{w}^T \\cdot \\vec{a}) &\\pod{5} \\\\\n        &= sigmoid(w_{84} a_4 + w_{85} a_5 + w_{86} a_6 + w_{87} a_7 + w_{8b}) &\\pod{6}\n\\end{aligned}\n$$\n\n同理，我们还可以计算出 $y_2$ 的值。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量 $\\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}$ 时，神经网络的输出向量 $\\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}$ 。这里我们也看到， **输出向量的维度和输出层神经元个数相同** 。\n\n### 神经网络的矩阵表示\n\n神经网络的计算如果用矩阵来表示会很方便（当然逼格也更高），我们先来看看隐藏层的矩阵表示。\n\n首先我们把隐藏层4个节点的计算依次排列出来：\n\n$$\n\\begin{aligned}\n    a_4 &= sigmoid(w_{41} x_1 + w_{42} x_2 + w_{43} x_3 + w_{4b}) \\\\\n    a_5 &= sigmoid(w_{51} x_1 + w_{52} x_2 + w_{53} x_3 + w_{5b}) \\\\\n    a_6 &= sigmoid(w_{61} x_1 + w_{62} x_2 + w_{63} x_3 + w_{6b}) \\\\\n    a_7 &= sigmoid(w_{71} x_1 + w_{72} x_2 + w_{73} x_3 + w_{7b})\n\\end{aligned}\n$$\n\n接着，定义网络的输入向量 $\\vec{x}$ 和隐藏层每个节点的权重向量 $\\vec{w_j}$ 。令\n\n$$\n\\begin{aligned}\n    \\vec{x} &= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ 1 \\end{bmatrix} &\\pod{7} \\\\\n    \\vec{w_4} &= [w_{41}, w_{42}, w_{43}, w_{4b}] &\\pod{8} \\\\\n    \\vec{w_5} &= [w_{51}, w_{52}, w_{53}, w_{5b}] &\\pod{9} \\\\\n    \\vec{w_6} &= [w_{61}, w_{62}, w_{63}, w_{6b}] &\\pod{10} \\\\\n    \\vec{w_7} &= [w_{71}, w_{72}, w_{73}, w_{7b}] &\\pod{11} \\\\\n    f &= sigmoid &\\pod{12}\n\\end{aligned}\n$$\n\n代入到前面的一组式子，得到：\n\n$$\n\\begin{aligned}\n    a_4 &= f(\\vec{w_4} \\cdot \\vec{x}) &\\pod{13} \\\\\n    a_5 &= f(\\vec{w_5} \\cdot \\vec{x}) &\\pod{14} \\\\\n    a_6 &= f(\\vec{w_6} \\cdot \\vec{x}) &\\pod{15} \\\\\n    a_7 &= f(\\vec{w_7} \\cdot \\vec{x}) &\\pod{16} \\\\\n\\end{aligned}\n$$\n\n现在，我们把上述计算 $a_4, a_5, a_6, a_7$ 的四个式子写到一个矩阵里面，每个式子作为矩阵的一行，就可以利用矩阵来表示它们的计算了。令\n\n$$\n\\vec{a_4} = \\begin{bmatrix} a_4 \\\\ a_5 \\\\ a_6 \\\\ a_7 \\end{bmatrix} ,\n\\vec{W} = \\begin{bmatrix} \\vec{w_4} \\\\ \\vec{w_5} \\\\ \\vec{w_6} \\\\ \\vec{w_7} \\end{bmatrix} \n=  \\begin{bmatrix}\n    w_{41}, w_{42}, w_{43}, w_{4b} \\\\\n    w_{51}, w_{52}, w_{53}, w_{5b} \\\\\n    w_{61}, w_{62}, w_{63}, w_{6b} \\\\\n    w_{71}, w_{72}, w_{73}, w_{7b}\n    \\end{bmatrix},\nf(\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ . \\\\ . \\\\ . \\end{bmatrix})\n= \\begin{bmatrix} f(x_1) \\\\ f(x_2) \\\\ f(x_3) \\\\ . \\\\ . \\\\ . \\end{bmatrix}\n$$\n\n带入前面的一组式子，得到\n\n$$\n\\vec{a} = f(W \\cdot \\vec{x}) \\tag{\\text{式 2}}\n$$\n\n在 **式2** 中， $f$ 是激活函数，在本例中是 $sigmoid$ 函数； $W$ 是某一层的权重矩阵； $\\vec{x}$ 是某层的输入向量； $\\vec{a}$ 是某层的输出向量。 **式2** 说明神经网络的每一层的作用实际上就是先将输入向量 **左乘** 一个数组进行线性变换，得到一个新的向量，然后再对这个向量 **逐元素** 应用一个激活函数。\n\n每一层的算法都是一样的。比如，对于包含一个输入层，一个输出层和三个隐藏层的神经网络，我们假设其权重矩阵分别为 $W_1, W_2, W_3, W_4$ ，每个隐藏层的输出分别是 $\\vec{a_1}, \\vec{a_2}, \\vec{a_3}$ ，神经网络的输入为 $\\vec{x}$ ，神经网络的输入为 $\\vec{y}$ ，如下图所示\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-c1388dc8fdcce427.png)\n\n则每一层的输出向量的计算可以表示为：\n\n$$\n\\begin{aligned}\n    \\vec{a_1} &= f(W_1 \\cdot \\vec{x}) &\\pod{17} \\\\\n    \\vec{a_2} &= f(W_2 \\cdot \\vec{a_1}) &\\pod{18} \\\\\n    \\vec{a_3} &= f(W_3 \\cdot \\vec{a_2}) &\\pod{19} \\\\\n    \\vec{y} &= f(W_4 \\cdot \\vec{a_3}) &\\pod{20}\n\\end{aligned}\n$$\n\n这就是神经网络输出值的计算方法。\n\n## 神经网络的训练\n\n现在，我们需要知道一个神经网络的每个连接上的权值是如何得到的。我们可以说神经网络是一个 **模型** ，那么这些权值就是模型的 **参数** ，也就是模型要学习的东西。然而，一个神经网络的连接方式、网络的层数、每层的节点数这些参数，则不是学习出来的，而是人为事先设置的。对于这些人为设置的参数，我们称之为 **超参数(Hyper-Parameters)** 。\n\n接下来，我们将要介绍神经网络的训练算法：反向传播算法。\n\n### 反向传播算法(Back Propagation)\n\n我们首先直观的介绍反向传播算法，最后再来介绍这个算法的推导。当然读者也可以完全跳过推导部分，因为即使不知道如何推导，也不影响你写出来一个神经网络的训练代码。事实上，现在神经网络成熟的开源实现多如牛毛，除了练手之外，你可能都没有机会需要去写一个神经网络。\n\n我们以 **监督学习** 为例来解释反向传播算法。在[零基础入门深度学习(2) - 线性单元和梯度下降](/2019/05/03/deeplearning-quickstart-2/)一文中我们介绍了什么是 **监督学习** ，如果忘记了可以再看一下。另外，我们设神经元的激活函数 $fs$ 为 $sigmoid$ 函数(不同激活函数的计算公式不同，详情[见反向传播算法的推导](#反向传播算法的推导)一节。\n\n我们假设每个训练样本为 $(\\vec{x}, \\vec{t})$ ，其中向量 $\\vec{x}$ 是训练样本的特征，而 $\\vec{t}$ 是样本的目标值。\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-6f27ced45cf5c0d8.png)\n\n首先，我们根据上一节介绍的算法，用样本的特征 $\\vec{x}$ ，计算出神经网络中每个隐藏层节点的输出 $a_i$ ，以及输出层每个节点的输出 $y_i$ 。\n\n然后，我们按照下面的方法计算出每个节点的误差项 $\\delta_i$ ：\n\n- 对于输出层节点 $i$ ，\n\n$$\n\\delta_i = y_i(1 - y_i)(t_i - y_i) \\tag{\\text{式 3}}\n$$\n\n其中，是 $\\delta_i$ 节点 $i$ 的误差项， $y_i$ 是节点 $i$ 的 **输出值** ， $t_i$ 是样本对应于节点 $i$ 的 **目标值** 。举个例子，根据上图，对于输出层节点8来说，它的输出值是 $y_1$ ，而样本的目标值是 $t_1$ ，带入上面的公式得到节点8的误差项 $\\delta_8$ 应该是：\n\n$$\n\\delta_8 = y_1(1 - y_1)(t_1 - y_1)\n$$\n\n- 对于隐藏层节点，\n\n$$\n\\delta_i = a_i(1-a_i)\\sum \\limits_{k\\in outputs} w_{ki} \\delta_k \\tag{\\text{式 4}}\n$$\n\n其中， $a_i$ 是节点 $i$ 的输出值， $w_{ki}$ 是节点 $i$ 到它的下一层节点 $k$ 的连接的权重， $\\delta_k$ 是节点 $i$ 的下一层节点 $k$ 的误差项。例如，对于隐藏层节点4来说，计算方法如下：\n\n$$\n\\delta_4 = a_4 (1 - a_4)(w_{84} \\delta_8 + w_{94} \\delta_9)\n$$\n\n最后，更新每个连接上的权值：\n\n$$\nw_{ji} \\leftarrow w_{ji} + \\eta \\delta_j x_{ji} \\tag{\\text{式 5}}\n$$\n\n其中， $w_{ji}$ 是节点 $i$ 到节点 $j$ 的权重， $\\eta$ 是一个称为 **学习速率** 的常数， $\\delta_j$ 是节点 $j$ 的误差项， $x_{ji}$ 是节点 $i$ 传递给节点 $j$ 的输入。例如，权重 $w_{84}$ 的更新方法如下：\n\n$$\nw_{84} \\leftarrow w_{84} + \\eta \\delta_8 a_4\n$$\n\n类似的，权重 $w_{41}$ 的更新方法如下：\n\n$$\nw_{41} \\leftarrow w_{41} + \\eta \\delta_4 a_1\n$$\n\n偏置项的输入值永远为1。例如，节点4的偏置项 $w_{4b}$ 应该按照下面的方法计算：\n\n$$\nw_{4b} \\leftarrow w_{4b} + \\eta \\delta_4\n$$\n\n我们已经介绍了神经网络每个节点误差项的计算和权重更新方法。显然，计算一个节点的误差项，需要先计算每个与其相连的下一层节点的误差项。这就要求误差项的计算顺序必须是从输出层开始，然后反向依次计算每个隐藏层的误差项，直到与输入层相连的那个隐藏层。这就是反向传播算法的名字的含义。当所有节点的误差项计算完毕后，我们就可以根据 **式5** 来更新所有的权重。\n\n以上就是基本的反向传播算法，并不是很复杂，您弄清楚了么？\n\n### 反向传播算法的推导\n\n反向传播算法其实就是链式求导法则的应用。然而，这个如此简单且显而易见的方法，却是在Roseblatt提出感知器算法将近30年之后才被发明和普及的。对此，Bengio这样回应道：\n\n>很多看似显而易见的想法只有在事后才变得显而易见。\n\n接下来，我们用链式求导法则来推导反向传播算法，也就是上一小节的 **式3** 、 **式4** 、 **式5** 。\n\n***前方高能预警——接下来是数学公式重灾区，读者可以酌情阅读，不必强求。***\n\n按照机器学习的通用套路，我们先确定神经网络的目标函数，然后用 **随机梯度下降** 优化算法去求目标函数最小值时的参数值。\n\n我们取网络所有输出层节点的误差平方和作为目标函数：\n\n$$\nE_d = \\frac{1}{2} \\sum \\limits_{i \\in outputs} (t_i - y_i)^2\n$$\n\n其中， $E_d$ 表示是样本 $d$ 的误差。\n\n然后，我们用文章[零基础入门深度学习(2) - 线性单元和梯度下降](/2019/05/03/deeplearning-quickstart-2)中介绍的 **随机梯度下降** 算法对目标函数进行优化：\n\n$$\nw_{ji} \\leftarrow w_{ji} - \\eta \\frac{\\partial E_d}{\\partial w_{ji}}\n$$\n\n随机梯度下降算法也就是需要求出误差 $E_d$ 对于每个权重 $w_{ji}$ 的偏导数（也就是梯度），怎么求呢？\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-6f27ced45cf5c0d8.png)\n\n观察上图，我们发现权重 $w_{ji}$ 仅能通过影响节点 $j$ 的输入值影响网络的其它部分，设 $net_j$ 是节点 $j$ 的 **加权输入** ，即\n\n$$\n\\begin{aligned}\n    net_j &= \\vec{w_j} \\cdot \\vec{x_j} &\\pod{21} \\\\\n          &= \\sum \\limits_{i} w_{ji} x_{ji} &\\pod{22}\n\\end{aligned}\n$$\n\n $E_d$ 是 $net_j$ 的函数，而 $net_j$ 是 $w_{ji}$ 的函数。根据链式求导法则，可以得到：\n\n$$\n\\begin{aligned}\n    \\frac{\\partial E_d}{\\partial w_{ji}}\n        &= \\frac{\\partial E_d}{\\partial net_j} \\frac{\\partial net_j}{\\partial w_{ji}} &\\pod{23} \\\\\n        &= \\frac{\\partial E_d}{\\partial net_j} \\frac{\\partial \\sum_i w_{ji} x_{ji}}{\\partial w_{ji}} &\\pod{24} \\\\\n        &= \\frac{\\partial E_d}{\\partial net_j} x_{ji} &\\pod{25}\n\\end{aligned}\n$$\n\n上式中， $x_{ji}$ 是节点 $i$ 传递给节点 $j$ 的输入值，也就是节点 $i$ 的输出值。\n对于 $\\frac{\\partial E_d}{\\partial net_j}$ 的推导，需要区分 **输出层** 和 **隐藏层** 两种情况。\n\n#### 输出层权值训练\n\n对于 **输出层** 来说， $net_j$ 仅能通过节点 $j$ 的输出值 $y_i$ 来影响网络其它部分，也就是说 $E_d$ 是 $y_j$ 的函数，而 $y_j$ 是 $net_j$ 的函数，其中 $y_j = sigmoid(net_j)$ 。所以我们可以再次使用链式求导法则：\n\n$$\n\\frac{\\partial E_d}{\\partial net_j}\n= \\frac{\\partial E_d}{\\partial y_j} \\frac{\\partial y_j}{\\partial net_j} \\pod{26}\n$$\n\n考虑上式第一项:\n\n$$\n\\begin{aligned}\n\\frac{\\partial E_d}{\\partial y_j}\n&= \\frac{\\partial}{\\partial y_j} \\frac{1}{2} \\sum \\limits_{i \\in outputs} (t_i - y_i)^2 &\\pod{27} \\\\\n&= \\frac{\\partial}{\\partial y_j} \\frac{1}{2} (t_j - y_j)^2 &\\pod{28} \\\\\n&= -(t_j - y_j) &\\pod{29}\n\\end{aligned}\n$$\n\n考虑上式第二项：\n\n$$\n\\begin{aligned}\n\\frac{\\partial y_j}{\\partial net_j}\n&= \\frac{\\partial sigmid(y_j)}{\\partial net_j} &\\pod{30} \\\\\n&= y_j(1 - y_j) &\\pod{31}\n\\end{aligned}\n$$\n\n将第一项和第二项带入，得到：\n\n$$\n\\frac{\\partial E_d}{\\partial net_j} = -(t_j - y_j) y_j (1 - y_j)\n$$\n\n如果令 $\\delta_j = - \\frac{\\partial E_d}{\\partial net_j}$ ，也就是一个节点的误差项 $\\delta$ 是网络误差对这个节点输入的偏导数的相反数。带入上式，得到：\n\n$$\n\\delta_j = (t_j - y_j) y_j (1 - y_j)\n$$\n\n上式就是 **式3** 。\n\n将上述推导带入随机梯度下降公式，得到：\n\n$$\n\\begin{aligned}\n    w_{ji} &\\leftarrow w_{ji} - \\eta \\frac{\\partial E_d}{\\partial w_{ji}} &\\pod{32} \\\\\n           &= w_{ji} + \\eta (t_j - y_j) y_j (1 - y_j) _{ji} &\\pod{33} \\\\\n           &= w_{ji} + \\eta \\delta_j x_{ji} &\\pod{34} \\\\\n\\end{aligned}\n$$\n\n上式就是 **式5** 。\n\n#### 隐藏层权值训练\n\n现在我们要推导出隐藏层的 $\\frac{\\partial E_d}{\\partial net_j}$ 。\n\n首先，我们需要定义节点 $j$ 的所有直接下游节点的集合 $Downstream(j)$ 。例如，对于节点4来说，它的直接下游节点是节点8、节点9。可以看到 $net_j$ 只能通过影响 $Downstream(j)$ 再影响 $E_d$ 。设 $net_k$ 是节点 $j$ 的下游节点的输入，则 $E_d$ 是 $net_k$ 的函数，而 $net_k$ 是 $net_j$ 的函数。因为 $net_k$ 有多个，我们应用全导数公式，可以做出如下推导：\n\n$$\n\\begin{aligned}\n\\frac{\\partial E_d}{\\partial net_j}\n&= \\sum \\limits_{k \\in Downstream(j)} \\frac{\\partial E_d}{\\partial net_k} \\frac{\\partial net_k}{\\partial net_j} &\\pod{35} \\\\\n\n&= \\sum \\limits_{k \\in Downstream(j)} - \\delta_k \\frac{\\partial net_k}{\\partial net_j} &\\pod{36} \\\\\n\n&= \\sum \\limits_{k \\in Downstream(j)} - \\delta_k \\frac{\\partial net_k}{\\partial a_j} \\frac{\\partial a_j}{\\partial net_j} &\\pod{37} \\\\\n\n&= \\sum \\limits_{k \\in Downstream(j)} - \\delta_k w_{kj} \\frac{\\partial a_j}{\\partial net_j} &\\pod{38} \\\\\n&= \\sum \\limits_{k \\in Downstream(j)} - \\delta_k w_{kj} a_j (1 - a_j) &\\pod{39} \\\\\n&= -a_j (1 - a_j) \\sum \\limits_{k \\in Downstream(j)} \\delta_k w_{kj} &\\pod{40} \\\\\n\\end{aligned}\n$$\n\n因为 $\\delta_j = - \\frac{\\partial E_d}{\\partial net_j}$ ，带入上式得到：\n\n$$\n\\delta_j = a_j (1 - a_j) \\sum \\limits_{k \\in Downstream(j)} \\delta_k w_{kj}\n$$\n\n上式就是 **式4** 。\n\n***——数学公式警报解除——***\n\n至此，我们已经推导出了反向传播算法。需要注意的是，我们刚刚推导出的训练规则是根据激活函数是sigmoid函数、平方和误差、全连接网络、随机梯度下降优化算法。如果激活函数不同、误差计算方式不同、网络连接结构不同、优化算法不同，则具体的训练规则也会不一样。但是无论怎样，训练规则的推导方式都是一样的，应用链式求导法则进行推导即可。\n\n## 神经网络的实现\n\n>完整代码请参考GitHub: https://github.com/hanbt/learn_dl/blob/master/bp.py (python2.7)\n\n现在，我们要根据前面的算法，实现一个基本的全连接神经网络，这并不需要太多代码。我们在这里依然采用面向对象设计。\n\n首先，我们先做一个基本的模型：\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-2fbae2ee722fbef9.png)\n\n如上图，可以分解出5个领域对象来实现神经网络：\n\n- *Network* 神经网络对象，提供API接口。它由若干层对象组成以及连接对象组成。\n- *Layer* 层对象，由多个节点组成。\n- *Node* 节点对象计算和记录节点自身的信息(比如输出值、误差项等)，以及与这个节点相关的上下游的连接。\n- *Connection* 每个连接对象都要记录该连接的权重。\n- *Connections* 仅仅作为Connection的集合对象，提供一些集合操作。\n\nNode实现如下：\n\n```python\n# 节点类，负责记录和维护节点自身信息以及与这个节点相关的上下游连接，实现输出值和误差项的计算。\nclass Node(object):\n    def __init__(self, layer_index, node_index):\n        '''\n        构造节点对象。\n        layer_index: 节点所属的层的编号\n        node_index: 节点的编号\n        '''\n        self.layer_index = layer_index\n        self.node_index = node_index\n        self.downstream = []\n        self.upstream = []\n        self.output = 0\n        self.delta = 0\n    def set_output(self, output):\n        '''\n        设置节点的输出值。如果节点属于输入层会用到这个函数。\n        '''\n        self.output = output\n    def append_downstream_connection(self, conn):\n        '''\n        添加一个到下游节点的连接\n        '''\n        self.downstream.append(conn)\n    def append_upstream_connection(self, conn):\n        '''\n        添加一个到上游节点的连接\n        '''\n        self.upstream.append(conn)\n    def calc_output(self):\n        '''\n        根据式1计算节点的输出\n        '''\n        output = reduce(lambda ret, conn: ret + conn.upstream_node.output * conn.weight, self.upstream, 0)\n        self.output = sigmoid(output)\n    def calc_hidden_layer_delta(self):\n        '''\n        节点属于隐藏层时，根据式4计算delta\n        '''\n        downstream_delta = reduce(\n            lambda ret, conn: ret + conn.downstream_node.delta * conn.weight,\n            self.downstream, 0.0)\n        self.delta = self.output * (1 - self.output) * downstream_delta\n    def calc_output_layer_delta(self, label):\n        '''\n        节点属于输出层时，根据式3计算delta\n        '''\n        self.delta = self.output * (1 - self.output) * (label - self.output)\n    def __str__(self):\n        '''\n        打印节点的信息\n        '''\n        node_str = '%u-%u: output: %f delta: %f' % (self.layer_index, self.node_index, self.output, self.delta)\n        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n        upstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.upstream, '')\n        return node_str + '\\n\\tdownstream:' + downstream_str + '\\n\\tupstream:' + upstream_str \n```\n\nConstNode对象，为了实现一个输出恒为1的节点(计算偏置项 $w_b$ 时需要)\n\n```python\nclass ConstNode(object):\n    def __init__(self, layer_index, node_index):\n        '''\n        构造节点对象。\n        layer_index: 节点所属的层的编号\n        node_index: 节点的编号\n        '''    \n        self.layer_index = layer_index\n        self.node_index = node_index\n        self.downstream = []\n        self.output = 1\n    def append_downstream_connection(self, conn):\n        '''\n        添加一个到下游节点的连接\n        '''       \n        self.downstream.append(conn)\n    def calc_hidden_layer_delta(self):\n        '''\n        节点属于隐藏层时，根据式4计算delta\n        '''\n        downstream_delta = reduce(\n            lambda ret, conn: ret + conn.downstream_node.delta * conn.weight,\n            self.downstream, 0.0)\n        self.delta = self.output * (1 - self.output) * downstream_delta\n    def __str__(self):\n        '''\n        打印节点的信息\n        '''\n        node_str = '%u-%u: output: 1' % (self.layer_index, self.node_index)\n        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n        return node_str + '\\n\\tdownstream:' + downstream_str\n```\n\nLayer对象，负责初始化一层。此外，作为Node的集合对象，提供对Node集合的操作。\n\n```python\nclass Layer(object):\n    def __init__(self, layer_index, node_count):\n        '''\n        初始化一层\n        layer_index: 层编号\n        node_count: 层所包含的节点个数\n        '''\n        self.layer_index = layer_index\n        self.nodes = []\n        for i in range(node_count):\n            self.nodes.append(Node(layer_index, i))\n        self.nodes.append(ConstNode(layer_index, node_count))\n    def set_output(self, data):\n        '''\n        设置层的输出。当层是输入层时会用到。\n        '''\n        for i in range(len(data)):\n            self.nodes[i].set_output(data[i])\n    def calc_output(self):\n        '''\n        计算层的输出向量\n        '''\n        for node in self.nodes[:-1]:\n            node.calc_output()\n    def dump(self):\n        '''\n        打印层的信息\n        '''\n        for node in self.nodes:\n            print node\n```\n\nConnection对象，主要职责是记录连接的权重，以及这个连接所关联的上下游节点。\n\n```python\nclass Connection(object):\n    def __init__(self, upstream_node, downstream_node):\n        '''\n        初始化连接，权重初始化为是一个很小的随机数\n        upstream_node: 连接的上游节点\n        downstream_node: 连接的下游节点\n        '''\n        self.upstream_node = upstream_node\n        self.downstream_node = downstream_node\n        self.weight = random.uniform(-0.1, 0.1)\n        self.gradient = 0.0\n    def calc_gradient(self):\n        '''\n        计算梯度\n        '''\n        self.gradient = self.downstream_node.delta * self.upstream_node.output\n    def get_gradient(self):\n        '''\n        获取当前的梯度\n        '''\n        return self.gradient\n    def update_weight(self, rate):\n        '''\n        根据梯度下降算法更新权重\n        '''\n        self.calc_gradient()\n        self.weight += rate * self.gradient\n    def __str__(self):\n        '''\n        打印连接信息\n        '''\n        return '(%u-%u) -> (%u-%u) = %f' % (\n            self.upstream_node.layer_index, \n            self.upstream_node.node_index,\n            self.downstream_node.layer_index, \n            self.downstream_node.node_index, \n            self.weight)\n```\n\nConnections对象，提供Connection集合操作。\n\n```python\nclass Connections(object):\n    def __init__(self):\n        self.connections = []\n    def add_connection(self, connection):\n        self.connections.append(connection)\n    def dump(self):\n        for conn in self.connections:\n            print conn\n```\n\nNetwork对象，提供API。\n\n```python\nclass Network(object):\n    def __init__(self, layers):\n        '''\n        初始化一个全连接神经网络\n        layers: 二维数组，描述神经网络每层节点数\n        '''\n        self.connections = Connections()\n        self.layers = []\n        layer_count = len(layers)\n        node_count = 0;\n        for i in range(layer_count):\n            self.layers.append(Layer(i, layers[i]))\n        for layer in range(layer_count - 1):\n            connections = [Connection(upstream_node, downstream_node) \n                           for upstream_node in self.layers[layer].nodes\n                           for downstream_node in self.layers[layer + 1].nodes[:-1]]\n            for conn in connections:\n                self.connections.add_connection(conn)\n                conn.downstream_node.append_upstream_connection(conn)\n                conn.upstream_node.append_downstream_connection(conn)\n    def train(self, labels, data_set, rate, iteration):\n        '''\n        训练神经网络\n        labels: 数组，训练样本标签。每个元素是一个样本的标签。\n        data_set: 二维数组，训练样本特征。每个元素是一个样本的特征。\n        '''\n        for i in range(iteration):\n            for d in range(len(data_set)):\n                self.train_one_sample(labels[d], data_set[d], rate)\n    def train_one_sample(self, label, sample, rate):\n        '''\n        内部函数，用一个样本训练网络\n        '''\n        self.predict(sample)\n        self.calc_delta(label)\n        self.update_weight(rate)\n    def calc_delta(self, label):\n        '''\n        内部函数，计算每个节点的delta\n        '''\n        output_nodes = self.layers[-1].nodes\n        for i in range(len(label)):\n            output_nodes[i].calc_output_layer_delta(label[i])\n        for layer in self.layers[-2::-1]:\n            for node in layer.nodes:\n                node.calc_hidden_layer_delta()\n    def update_weight(self, rate):\n        '''\n        内部函数，更新每个连接权重\n        '''\n        for layer in self.layers[:-1]:\n            for node in layer.nodes:\n                for conn in node.downstream:\n                    conn.update_weight(rate)\n    def calc_gradient(self):\n        '''\n        内部函数，计算每个连接的梯度\n        '''\n        for layer in self.layers[:-1]:\n            for node in layer.nodes:\n                for conn in node.downstream:\n                    conn.calc_gradient()\n    def get_gradient(self, label, sample):\n        '''\n        获得网络在一个样本下，每个连接上的梯度\n        label: 样本标签\n        sample: 样本输入\n        '''\n        self.predict(sample)\n        self.calc_delta(label)\n        self.calc_gradient()\n    def predict(self, sample):\n        '''\n        根据输入的样本预测输出值\n        sample: 数组，样本的特征，也就是网络的输入向量\n        '''\n        self.layers[0].set_output(sample)\n        for i in range(1, len(self.layers)):\n            self.layers[i].calc_output()\n        return map(lambda node: node.output, self.layers[-1].nodes[:-1])\n    def dump(self):\n        '''\n        打印网络信息\n        '''\n        for layer in self.layers:\n            layer.dump()\n```\n\n至此，实现了一个基本的全连接神经网络。可以看到，同神经网络的强大学习能力相比，其实现还算是很容易的。\n\n### 梯度检查\n\n怎么保证自己写的神经网络没有BUG呢？事实上这是一个非常重要的问题。一方面，千辛万苦想到一个算法，结果效果不理想，那么是算法本身错了还是代码实现错了呢？定位这种问题肯定要花费大量的时间和精力。另一方面，由于神经网络的复杂性，我们几乎无法事先知道神经网络的输入和输出，因此类似TDD(测试驱动开发)这样的开发方法似乎也不可行。\n\n办法还是有滴，就是利用梯度检查来确认程序是否正确。梯度检查的思路如下：\n\n对于梯度下降算法：\n\n$$\nw_{ji} \\leftarrow w_{ji} - \\eta \\frac{\\partial E_d}{\\partial w_{ji}}\n$$\n\n来说，这里关键之处在于 $\\frac{\\partial E_d}{\\partial w_{ji}}$ 的计算一定要正确，而它是 $E_d$ 对 $w_{ji}$ 的偏导数。而根据导数的定义：\n\n$$\nf'(\\theta) = \\lim\\limits_{\\epsilon \\rightarrow 0} \\frac{f(\\theta + \\epsilon) - f(\\theta - \\epsilon)}{2 \\epsilon}\n$$\n\n对于任意 $\\theta$ 的导数值，我们都可以用等式右边来近似计算。我们把 $E_d$ 看做是 $w_{ji}$ 的函数，即 $E_d(w_{ji})$ ，那么根据导数定义， $\\frac{\\partial E_d (w_{ji})}{\\partial w_{ji}}$ 应该等于：\n\n$$\n\\frac{\\partial E_d (w_{ji})}{\\partial w_{ji}}\n=\n\\lim\\limits_{\\epsilon \\rightarrow 0} \\frac{f(\\theta + \\epsilon) - f(\\theta - \\epsilon)}{2 \\epsilon}\n$$\n\n如果把 $\\epsilon$ 设置为一个很小的数（比如 $10^{-4}$ ），那么上式可以写成：\n\n$$\n\\frac{\\partial E_d (w_{ji})}{\\partial w_{ji}}\n\\approx\n\\frac{f(\\theta + \\epsilon) - f(\\theta - \\epsilon)}{2 \\epsilon}\n$$\n\n我们就可以利用式6，来计算梯度 $\\frac{\\partial E_d}{\\partial w_{ji}}$ 的值，然后同我们神经网络代码中计算出来的梯度值进行比较。如果两者的差别 **非常的小** ，那么就说明我们的代码是正确的。\n\n下面是梯度检查的代码。如果我们想检查参数 $w_{ji}$ 的梯度是否正确，我们需要以下几个步骤：\n\n1. 首先使用一个样本对神经网络进行训练，这样就能获得每个权重的梯度。\n2. 将 $w_{ji}$ 加上一个很小的值( $10^{-4}$ )，重新计算神经网络在这个样本 $d$ 下的 $E_{d+}$ 。\n3. 将 $w_{ji}$ 减上一个很小的值( $10^{-4}$ )，重新计算神经网络在这个样本 $d$ 下的 $E_{d-}$ 。\n4. 根据式6计算出期望的梯度值，和第一步获得的梯度值进行比较，它们应该几乎想等(至少4位有效数字相同)。\n\n当然，我们可以重复上面的过程，对每个权重 $w_{ji}$ 都进行检查。也可以使用多个样本重复检查。\n\n```python\ndef gradient_check(network, sample_feature, sample_label):\n    '''\n    梯度检查\n    network: 神经网络对象\n    sample_feature: 样本的特征\n    sample_label: 样本的标签\n    '''\n    # 计算网络误差\n    network_error = lambda vec1, vec2: \\\n            0.5 * reduce(lambda a, b: a + b, \n                      map(lambda v: (v[0] - v[1]) * (v[0] - v[1]),\n                          zip(vec1, vec2)))\n    # 获取网络在当前样本下每个连接的梯度\n    network.get_gradient(sample_feature, sample_label)\n    # 对每个权重做梯度检查    \n    for conn in network.connections.connections: \n        # 获取指定连接的梯度\n        actual_gradient = conn.get_gradient()\n        # 增加一个很小的值，计算网络的误差\n        epsilon = 0.0001\n        conn.weight += epsilon\n        error1 = network_error(network.predict(sample_feature), sample_label)\n        # 减去一个很小的值，计算网络的误差\n        conn.weight -= 2 * epsilon # 刚才加过了一次，因此这里需要减去2倍\n        error2 = network_error(network.predict(sample_feature), sample_label)\n        # 根据式6计算期望的梯度值\n        expected_gradient = (error2 - error1) / (2 * epsilon)\n        # 打印\n        print 'expected gradient: \\t%f\\nactual gradient: \\t%f' % (\n            expected_gradient, actual_gradient)\n```\n\n至此，会推导、会实现、会抓BUG，你已经摸到深度学习的大门了。接下来还需要不断的实践，我们用刚刚写过的神经网络去识别手写数字。\n\n## 神经网络实战——手写数字识别\n\n针对这个任务，我们采用业界非常流行的MNIST数据集。MNIST大约有60000个手写字母的训练样本，我们使用它训练我们的神经网络，然后再用训练好的网络去识别手写数字。\n\n手写数字识别是个比较简单的任务，数字只可能是0-9中的一个，这是个10分类问题。\n\n### 超参数的确定\n\n我们首先需要确定网络的层数和每层的节点数。关于第一个问题，实际上并没有什么理论化的方法，大家都是根据经验来拍，如果没有经验的话就随便拍一个。然后，你可以多试几个值，训练不同层数的神经网络，看看哪个效果最好就用哪个。嗯，现在你可能明白为什么说深度学习是个手艺活了，有些手艺很让人无语，而有些手艺还是很有技术含量的。\n\n不过，有些基本道理我们还是明白的，我们知道网络层数越多越好，也知道层数越多训练难度越大。对于全连接网络，隐藏层最好不要超过三层。那么，我们可以先试试仅有一个隐藏层的神经网络效果怎么样。毕竟模型小的话，训练起来也快些(刚开始玩模型的时候，都希望快点看到结果)。\n\n输入层节点数是确定的。因为MNIST数据集每个训练数据是28*28的图片，共784个像素，因此，输入层节点数应该是784，每个像素对应一个输入节点。\n\n输出层节点数也是确定的。因为是10分类，我们可以用10个节点，每个节点对应一个分类。输出层10个节点中，输出最大值的那个节点对应的分类，就是模型的预测结果。\n\n隐藏层节点数量是不好确定的，从1到100万都可以。下面有几个经验公式：\n\n$$\n\\begin{aligned}\nm &= \\sqrt{n+l} + \\alpha &\\pod{41} \\\\\nm &= log_2 n &\\pod{42} \\\\\nm &= \\sqrt{nl} &\\pod{43} \\\\\nm &: \\text{隐藏层节点数} &\\pod{44} \\\\\nn &: \\text{输入层节点数} &\\pod{45} \\\\\nl &: \\text{输出层节点数} &\\pod{46} \\\\\n\\alpha &: \\text{1 到 10之间的常数} &\\pod{47}\n\\end{aligned}\n$$\n\n因此，我们可以先根据上面的公式设置一个隐藏层节点数。如果有时间，我们可以设置不同的节点数，分别训练，看看哪个效果最好就用哪个。我们先拍一个，设隐藏层节点数为300吧。\n\n对于3层 $784 * 300 * 10$ 的全连接网络，总共有 $300 * (784 + 1) + 10 * (300 + 1) = 238510$ 个参数！神经网络之所以强大，是它提供了一种非常简单的方法去实现大量的参数。目前百亿参数、千亿样本的超大规模神经网络也是有的。因为MNIST只有6万个训练样本，参数太多了很容易过拟合，效果反而不好。\n\n### 模型的训练和评估\n\nMNIST数据集包含10000个测试样本。我们先用60000个训练样本训练我们的网络，然后再用测试样本对网络进行测试，计算识别错误率：\n\n$$\n\\text{错误率} = \\frac{\\text{错误预测样本数}}{\\text{总样本数}}\n$$\n\n我们每训练10轮，评估一次准确率。当准确率开始下降时（出现了过拟合）终止训练。\n\n### 代码实现\n\n首先，我们需要把MNIST数据集处理为神经网络能够接受的形式。MNIST训练集的文件格式可以参考官方网站，这里不在赘述。每个训练样本是一个28*28的图像，我们按照行优先，把它转化为一个784维的向量。每个标签是0-9的值，我们将其转换为一个10维的one-hot向量：如果标签值为 $n$ ，我们就把向量的第 $n$ 维（从0开始编号）设置为0.9，而其它维设置为0.1。例如，向量[0.1, 0.1, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]表示值2。\n\n下面是处理MNIST数据的代码：\n\n```python\n#!/usr/bin/env python\n# -*- coding: UTF-8 -*-\nimport struct\nfrom bp import *\nfrom datetime import datetime\n# 数据加载器基类\nclass Loader(object):\n    def __init__(self, path, count):\n        '''\n        初始化加载器\n        path: 数据文件路径\n        count: 文件中的样本个数\n        '''\n        self.path = path\n        self.count = count\n    def get_file_content(self):\n        '''\n        读取文件内容\n        '''\n        f = open(self.path, 'rb')\n        content = f.read()\n        f.close()\n        return content\n    def to_int(self, byte):\n        '''\n        将unsigned byte字符转换为整数\n        '''\n        return struct.unpack('B', byte)[0]\n# 图像数据加载器\nclass ImageLoader(Loader):\n    def get_picture(self, content, index):\n        '''\n        内部函数，从文件中获取图像\n        '''\n        start = index * 28 * 28 + 16\n        picture = []\n        for i in range(28):\n            picture.append([])\n            for j in range(28):\n                picture[i].append(\n                    self.to_int(content[start + i * 28 + j]))\n        return picture\n    def get_one_sample(self, picture):\n        '''\n        内部函数，将图像转化为样本的输入向量\n        '''\n        sample = []\n        for i in range(28):\n            for j in range(28):\n                sample.append(picture[i][j])\n        return sample\n    def load(self):\n        '''\n        加载数据文件，获得全部样本的输入向量\n        '''\n        content = self.get_file_content()\n        data_set = []\n        for index in range(self.count):\n            data_set.append(\n                self.get_one_sample(\n                    self.get_picture(content, index)))\n        return data_set\n# 标签数据加载器\nclass LabelLoader(Loader):\n    def load(self):\n        '''\n        加载数据文件，获得全部样本的标签向量\n        '''\n        content = self.get_file_content()\n        labels = []\n        for index in range(self.count):\n            labels.append(self.norm(content[index + 8]))\n        return labels\n    def norm(self, label):\n        '''\n        内部函数，将一个值转换为10维标签向量\n        '''\n        label_vec = []\n        label_value = self.to_int(label)\n        for i in range(10):\n            if i == label_value:\n                label_vec.append(0.9)\n            else:\n                label_vec.append(0.1)\n        return label_vec\ndef get_training_data_set():\n    '''\n    获得训练数据集\n    '''\n    image_loader = ImageLoader('train-images-idx3-ubyte', 60000)\n    label_loader = LabelLoader('train-labels-idx1-ubyte', 60000)\n    return image_loader.load(), label_loader.load()\ndef get_test_data_set():\n    '''\n    获得测试数据集\n    '''\n    image_loader = ImageLoader('t10k-images-idx3-ubyte', 10000)\n    label_loader = LabelLoader('t10k-labels-idx1-ubyte', 10000)\n    return image_loader.load(), label_loader.load()\n```\n\n网络的输出是一个10维向量，这个向量第 $n$ 个(从0开始编号)元素的值最大，那么 $n$ 就是网络的识别结果。下面是代码实现：\n\n```python\ndef get_result(vec):\n    max_value_index = 0\n    max_value = 0\n    for i in range(len(vec)):\n        if vec[i] > max_value:\n            max_value = vec[i]\n            max_value_index = i\n    return max_value_index\n```\n\n我们使用错误率来对网络进行评估，下面是代码实现：\n\n```python\ndef evaluate(network, test_data_set, test_labels):\n    error = 0\n    total = len(test_data_set)\n    for i in range(total):\n        label = get_result(test_labels[i])\n        predict = get_result(network.predict(test_data_set[i]))\n        if label != predict:\n            error += 1\n    return float(error) / float(total)\n```\n\n最后实现我们的训练策略：每训练10轮，评估一次准确率，当准确率开始下降时终止训练。下面是代码实现：\n\n```python\ndef train_and_evaluate():\n    last_error_ratio = 1.0\n    epoch = 0\n    train_data_set, train_labels = get_training_data_set()\n    test_data_set, test_labels = get_test_data_set()\n    network = Network([784, 300, 10])\n    while True:\n        epoch += 1\n        network.train(train_labels, train_data_set, 0.3, 1)\n        print '%s epoch %d finished' % (now(), epoch)\n        if epoch % 10 == 0:\n            error_ratio = evaluate(network, test_data_set, test_labels)\n            print '%s after epoch %d, error ratio is %f' % (now(), epoch, error_ratio)\n            if error_ratio > last_error_ratio:\n                break\n            else:\n                last_error_ratio = error_ratio\nif __name__ == '__main__':\n    train_and_evaluate()\n```\n\n在我的机器上测试了一下，1个epoch大约需要9000多秒，所以要对代码做很多的性能优化工作（比如用向量化编程）。训练要很久很久，可以把它上传到服务器上，在tmux的session里面去运行。为了防止异常终止导致前功尽弃，我们每训练10轮，就把获得参数值保存在磁盘上，以便后续可以恢复。(代码略)\n\n## 向量化编程\n\n>完整代码请参考GitHub: https://github.com/hanbt/learn_dl/blob/master/fc.py (python2.7)\n\n在经历了漫长的训练之后，我们可能会想到，肯定有更好的办法！是的，程序员们，现在我们需要告别面向对象编程了，转而去使用另外一种更适合深度学习算法的编程方式：向量化编程。主要有两个原因：一个是我们事实上并不需要真的去定义Node、Connection这样的对象，直接把数学计算实现了就可以了；另一个原因，是底层算法库会针对向量运算做优化（甚至有专用的硬件，比如GPU），程序效率会提升很多。所以，在深度学习的世界里，我们总会想法设法的把计算表达为向量的形式。我相信优秀的程序员不会把自己拘泥于某种（自己熟悉的）编程范式上，而会去学习并使用最为合适的范式。\n\n下面，我们用向量化编程的方法，重新实现前面的 **全连接神经网络** 。\n\n首先，我们需要把所有的计算都表达为向量的形式。对于全连接神经网络来说，主要有三个计算公式。\n\n前向计算，我们发现 **式2** 已经是向量化的表达了：\n\n$$\n\\vec{a} = \\sigma (W \\cdot \\vec{x}) \\tag{\\text{式 2}}\n$$\n\n上式中的 $\\sigma$ 表示sigmoid函数。\n\n反向计算，我们需要把式3和式4使用向量来表示：\n\n$$\n\\begin{aligned}\n\\vec{\\sigma}\n& = \\vec{y} (1 - \\vec{y}) (\\vec{t} - \\vec{y}) &\\pod{式 7} \\\\\n\\vec{\\sigma^{(l)}}\n& = \\vec{a^{(l)}} (1 - \\vec{a^{(l)}}) W^T \\delta^{(l+1)} &\\pod{式 8}\n\\end{aligned}\n$$\n\n在 **式8** 中， $\\delta^{(l)}$ 表示第 $l$ 层的误差项； $W^T$ 表示矩阵 $W$ 的转置。\n\n我们还需要权重数组 $W$ 和偏置项 $b$ 的梯度计算的向量化表示。也就是需要把 **式5** 使用向量化表示：\n\n$$\nw_{ji} \\leftarrow w_{ji} + \\eta \\delta_j x_{ji} \\tag{\\text{式 5}}\n$$\n\n其对应的向量化表示为：\n\n$$\nW \\leftarrow W + \\eta \\vec{\\delta} \\vec{x}^T \\tag{\\text{式 9}}\n$$\n\n更新偏置项的向量化表示为：\n\n$$\n\\vec{b} \\leftarrow \\vec{b} + \\eta \\vec{\\delta} \\tag{\\text{式 10}}\n$$\n\n现在，我们根据上面几个公式，重新实现一个类：FullConnectedLayer。它实现了全连接层的前向和后向计算：\n\n```python\n# 全连接层实现类\nclass FullConnectedLayer(object):\n    def __init__(self, input_size, output_size, \n                 activator):\n        '''\n        构造函数\n        input_size: 本层输入向量的维度\n        output_size: 本层输出向量的维度\n        activator: 激活函数\n        '''\n        self.input_size = input_size\n        self.output_size = output_size\n        self.activator = activator\n        # 权重数组W\n        self.W = np.random.uniform(-0.1, 0.1,\n            (output_size, input_size))\n        # 偏置项b\n        self.b = np.zeros((output_size, 1))\n        # 输出向量\n        self.output = np.zeros((output_size, 1))\n    def forward(self, input_array):\n        '''\n        前向计算\n        input_array: 输入向量，维度必须等于input_size\n        '''\n        # 式2\n        self.input = input_array\n        self.output = self.activator.forward(\n            np.dot(self.W, input_array) + self.b)\n    def backward(self, delta_array):\n        '''\n        反向计算W和b的梯度\n        delta_array: 从上一层传递过来的误差项\n        '''\n        # 式8\n        self.delta = self.activator.backward(self.input) * np.dot(\n            self.W.T, delta_array)\n        self.W_grad = np.dot(delta_array, self.input.T)\n        self.b_grad = delta_array\n    def update(self, learning_rate):\n        '''\n        使用梯度下降算法更新权重\n        '''\n        self.W += learning_rate * self.W_grad\n        self.b += learning_rate * self.b_grad\n\n```\n\n上面这个类一举取代了原先的Layer、Node、Connection等类，不但代码更加容易理解，而且运行速度也快了几百倍。\n\n现在，我们对Network类稍作修改，使之用到FullConnectedLayer：\n\n```python\n# Sigmoid激活函数类\nclass SigmoidActivator(object):\n    def forward(self, weighted_input):\n        return 1.0 / (1.0 + np.exp(-weighted_input))\n    def backward(self, output):\n        return output * (1 - output)\n# 神经网络类\nclass Network(object):\n    def __init__(self, layers):\n        '''\n        构造函数\n        '''\n        self.layers = []\n        for i in range(len(layers) - 1):\n            self.layers.append(\n                FullConnectedLayer(\n                    layers[i], layers[i+1],\n                    SigmoidActivator()\n                )\n            )\n    def predict(self, sample):\n        '''\n        使用神经网络实现预测\n        sample: 输入样本\n        '''\n        output = sample\n        for layer in self.layers:\n            layer.forward(output)\n            output = layer.output\n        return output\n    def train(self, labels, data_set, rate, epoch):\n        '''\n        训练函数\n        labels: 样本标签\n        data_set: 输入样本\n        rate: 学习速率\n        epoch: 训练轮数\n        '''\n        for i in range(epoch):\n            for d in range(len(data_set)):\n                self.train_one_sample(labels[d], \n                    data_set[d], rate)\n    def train_one_sample(self, label, sample, rate):\n        self.predict(sample)\n        self.calc_gradient(label)\n        self.update_weight(rate)\n    def calc_gradient(self, label):\n        delta = self.layers[-1].activator.backward(\n            self.layers[-1].output\n        ) * (label - self.layers[-1].output)\n        for layer in self.layers[::-1]:\n            layer.backward(delta)\n            delta = layer.delta\n        return delta\n    def update_weight(self, rate):\n        for layer in self.layers:\n            layer.update(rate)\n```\n\n现在，Network类也清爽多了，用我们的新代码再次训练一下MNIST数据集吧。\n\n## 小结\n\n至此，你已经完成了又一次漫长的学习之旅。你现在应该已经明白了神经网络的基本原理，高兴的话，你甚至有能力去动手实现一个，并用它解决一些问题。如果感到困难也不要气馁，这篇文章是一个重要的分水岭，如果你完全弄明白了的话，在真正的『小白』和装腔作势的『大牛』面前吹吹牛是完全没有问题的。\n\n作为深度学习入门的系列文章，本文也是上半场的结束。在这个半场，你掌握了机器学习、神经网络的 **基本** 概念，并且有能力去动手解决一些简单的问题（例如手写数字识别，如果用传统的观点来看，其实这些问题也不简单）。而且，一旦掌握基本概念，后面的学习就容易多了。\n\n在下半场，我们讲介绍更多『深度』学习的内容，我们已经讲了神经网络(Neutrol Network)，但是并没有讲深度神经网络(Deep Neutrol Network)。Deep会带来更加强大的能力，同时也带来更多的问题。如果不理解这些问题和它们的解决方案，也不能说你入门了『深度』学习。\n\n目前业界有很多开源的神经网络实现，它们的功能也要强大的多，因此你并不需要事必躬亲的去实现自己的神经网络。我们在上半场不断的从头发明轮子，是为了让你明白神经网络的基本原理，这样你就能非常迅速的掌握这些工具。在下半场的文章中，我们改变了策略：不会再去从头开始去实现，而是尽可能应用现有的工具。\n\n下一篇文章，我们介绍不同结构的神经网络，比如鼎鼎大名的 **卷积神经网络** ，它在图像和语音领域已然创造了诸多奇迹，在自然语言处理领域的研究也如火如荼。某种意义上说，它的成功大大提升了人们对于深度学习的信心。\n\n## 参考资料\n\n1. Tom M. Mitchell, \"机器学习\", 曾华军等译, 机械工业出版社\n2. CS 224N / Ling 284, Neural Networks for Named Entity Recognition\n3. LeCun et al. Gradient-Based Learning Applied to Document Recognition 1998","tags":["深度学习入门"],"categories":["转载"]},{"title":"转载 - 零基础入门深度学习(2) - 线性单元和梯度下降","url":"%2F2019%2F05%2F03%2Fdeeplearning-quickstart-2%2F","content":"\n![](/static/upload-images.jianshu.io/upload_images/2256672-06627c71f0d8c0dc.jpg)\n\n> 无论即将到来的是大数据时代还是人工智能时代，亦或是传统行业使用人工智能在云上处理大数据的时代，作为一个有理想有追求的程序员，\n不懂深度学习（Deep Learning）这个超热的技术，会不会感觉马上就out了？现在救命稻草来了，《零基础入门深度学习》\n系列文章旨在讲帮助爱编程的你从零基础达到入门级水平。零基础意味着你不需要太多的数学知识，只要会写程序就行了，没错，\n这是专门为程序员写的文章。虽然文中会有很多公式你也许看不懂，但同时也会有更多的代码，程序员的你一定能看懂的\n（我周围是一群狂热的Clean Code程序员，所以我写的代码也不会很差）。\n\n## 往期回顾\n\n在上一篇文章中，我们已经学会了编写一个简单的感知器，并用它来实现一个线性分类器。你应该还记得用来训练感知器的『感知器规则』。\n然而，我们并没有关心这个规则是怎么得到的。本文通过介绍另外一种『感知器』，也就是『线性单元』，来说明关于机器学习一些基本的概念，\n比如模型、目标函数、优化算法等等。这些概念对于所有的机器学习算法来说都是通用的，掌握了这些概念，就掌握了机器学习的基本套路。\n\n## 线性单元是啥\n\n<!-- more -->\n\n感知器有一个问题，当面对的数据集不是 **线性可分** 的时候，『感知器规则』可能无法收敛，\n这意味着我们永远也无法完成一个感知器的训练。为了解决这个问题，我们使用一个 **可导** 的 **线性函数** 来替代感知器的 **阶跃函数** ，\n这种感知器就叫做 **线性单元** 。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。\n\n为了简单起见，我们可以设置线性单元的激活函数 $f$ 为\n\n$$\n    f(x) = x\n$$\n\n这样的线性单元如下图所示\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-f57602e423d739ee.png)\n\n对比此前我们讲过的感知器\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-801d65e79bfc3162.png)\n\n这样替换了激活函数 $f$ 之后， **线性单元** 将返回一个 **实数值** 而不是 **0,1分类** 。因此线性单元用来解决 **回归** 问题而不是 **分类** 问题。\n\n### 线性单元的模型\n\n当我们说 **模型** 时，我们实际上在谈论根据输入 $x$ 预测输出 $y$ 的 **算法** 。比如， $x$ 可以是一个人的工作年限， $y$ 可以是他的月薪，我们可以用某种算法来根据一个人的工作年限来预测他的收入。比如：\n\n$$\n    y = h(x) = w * x + b\n$$\n\n函数 $h(x)$ 叫做 **假设** ，而 $w$ 、 $b$ 是它的 **参数** 。我们假设参数 $w = 1000$ ，参数 $b = 500$ ，如果一个人的工作年限是5年的话，我们的模型会预测他的月薪为\n\n$$\n    y = h(x) = 1000 * 5 + 500 = 5500(\\text{元})\n$$\n\n你也许会说，这个模型太不靠谱了。是这样的，因为我们考虑的因素太少了，仅仅包含了工作年限。如果考虑更多的因素，比如所处的行业、公司、职级等等，可能预测就会靠谱的多。我们把工作年限、行业、公司、职级这些信息，称之为 **特征** 。对于一个工作了5年，在IT行业，百度工作，职级T6这样的人，我们可以用这样的一个特征向量来表示他 $\\mathrm{x} = (5, IT, \\text{百度}, T6)$ 。\n\n既然输入 $\\mathrm{x}$ 变成了一个具备四个特征的向量，相对应的，仅仅一个参数 $w$ 就不够用了，我们应该使用4个参数 $w_1, w_2, w_3, w_4$ ，每个特征对应一个。这样，我们的模型就变成\n\n$$\n    y = h(x) = w_1 * x_1 + w_2 * x_2 + w_3 * x_3 + w_4 * x_4 + b\n$$\n\n其中， $x_1$ 对应工作年限， $x_2$ 对应行业， $x_3$ 对应公司， $x_4$ 对应职级。\n\n为了书写和计算方便，我们可以令 $w_0$ 等于 $b$ ，同时令 $w_0$ 对应于特征 $x_0$ 。由于 $x_0$ 其实并不存在，我们可以令它的值永远为1。也就是说\n\n$$\n    b = w_0 * x_0, \\text{其中} x_0 = 1\n$$\n\n这样上面的式子就可以写成\n\n$$\n\\begin{aligned}\n    y &= h(x) = w_1 * x_1 + w_2 * x_2 + w_3 * x_3 + w_4 * x_4 + b &\\pod{1} \\\\\n    & = w_0 * x_0 + w_1 * x_1 + w_2 * x_2 + w_3 * x_3 + w_4 * x_4 &\\pod{2}\n\\end{aligned}\n$$\n\n我们还可以把上式写成向量的形式\n\n$$\n    y = h(x) = \\mathrm{w}^\\mathrm{T} \\mathrm{x} \\tag{\\text{式 1}}\n$$\n\n长成这种样子模型就叫做 **线性模型** ，因为输出 $y$ 就是输入特 $x_1, x_2, x_3, \\dots$ 征的 **线性组合** 。\n\n### 监督学习和无监督学习\n\n接下来，我们需要关心的是这个模型如何训练，也就是参数 $w$ 取什么值最合适。\n\n机器学习有一类学习方法叫做 **监督学习** ，它是说为了训练一个模型，我们要提供这样一堆训练样本：每个训练样本既包括输入特征 $\\mathrm{x}$ ，也包括对应的输出 $y$ ( $y$ 也叫做 **标记** ， **label** )。也就是说，我们要找到很多人，我们既知道他们的特征(工作年限，行业...)，也知道他们的收入。我们用这样的样本去训练模型，让模型既看到我们提出的每个问题(输入特征 $\\mathrm{x}$ )，也看到对应问题的答案(标记 $y$ )。当模型看到足够多的样本之后，它就能总结出其中的一些规律。然后，就可以预测那些它没看过的输入所对应的答案了。\n\n另外一类学习方法叫做 **无监督学习** ，这种方法的训练样本中只有 $\\mathrm{x}$ 而没有 $y$ 。模型可以总结出特征的一些规律，但是无法知道其对应的答案 $y$ 。\n\n很多时候，既有 $\\mathrm{x}$ 又有 $y$ 的训练样本是很少的，大部分样本都只有 $\\mathrm{x}$ 。比如在语音到文本(STT)的识别任务中， $\\mathrm{x}$ 是语音， $y$ 是这段语音对应的文本。我们很容易获取大量的语音录音，然而把语音一段一段切分好并 **标注** 上对应文字则是非常费力气的事情。这种情况下，为了弥补带标注样本的不足，我们可以用 **无监督学习方法** 先做一些 **聚类** ，让模型总结出哪些音节是相似的，然后再用少量的带标注的训练样本，告诉模型其中一些音节对应的文字。这样模型就可以把相似的音节都对应到相应文字上，完成模型的训练。\n\n### 线性单元的目标函数\n\n现在，让我们只考虑 **监督学习** 。\n\n在监督学习下，对于一个样本，我们知道它的特征 $\\mathrm{x}$ ，以及标记 $y$ 。同时，我们还可以根据模型 $h(x)$ 计算得到输出 $\\bar{y}$ 。注意这里面我们用 $y$ 表示训练样本里面的 **标记** ，也就是实际值；用带上划线的 $\\bar{y}$ 表示模型计算的出来的 **预测值** 。我们当然希望模型计算出来的 $\\bar{y}$ 和 $y$ 越接近越好。\n\n数学上有很多方法来表示 $\\bar{y}$ 和 $y$ 接近程度，比如我们可以用 $\\bar{y}$ 和 $y$ 的差的平方的来表示它们的接近程度\n\n$$\ne = \\frac{1}{2}(y - \\bar{y})^2\n$$\n\n我们把 $e$ 叫做 **单个样本的误差** 。至于为什么前面要乘 $\\frac{1}{2}$ ，是为了后面计算方便。\n\n训练数据中会有很多样本，比如 $N$ 个，我们可以用训练数据中 **所有样本** 的误差的 **和** ，来表示模型的误差 $E$ ，也就是\n\n$$\nE = e^{(1)} + e^{(2)} + e^{(3)} + \\dots + e^{(n)}\n$$\n\n上式的 $e^{(1)}$ 表示第一个样本的误差， $e^{(2)}$ 表示第二个样本的误差......。\n\n我们还可以把上面的式子写成和式的形式。使用和式，不光书写起来简单，逼格也跟着暴涨，一举两得。所以一定要写成下面这样\n\n$$\n\\begin{aligned}\n    E &= e^{(1)} + e^{(2)} + e^{(3)} + \\dots + e^{(n)} &\\pod{3} \\\\\n    &= \\sum \\limits_{i=0}^{n} e^{(i)} &\\pod{4} \\\\\n    &= \\frac{1}{2} \\sum \\limits_{i=0}^{n} (y^{(i)} - \\bar{y}^{(i)})^2 \\pod{\\text{式2}} &\\pod{5}\n\\end{aligned}\n$$\n\n其中\n\n$$\n\\begin{aligned}\n    \\bar{y}^{(i)} &= h(x^{(i)}) &\\pod{6} \\\\\n    &=\\mathrm{w}^T\\mathrm{x}^{(i)} &\\pod{7}\n\\end{aligned}\n$$\n\n(式2)中， $x^{(i)}$ 表示第 $i$ 个训练样本的 **特征** ， $y^{(i)}$ 表示第 $i$ 个样本的 **标记** ，我们也可以用元组 $(x^{(i)}, y^{(i)})$ 表示第 $i$ 个 **训练样本** 。 $\\bar{y}^{(i)}$ 则是模型对第 $i$ 个样本的 **预测值** 。\n\n我们当然希望对于一个训练数据集来说，误差最小越好，也就是(式2)的值越小越好。对于特定的训练数据集来说， $(x^{(i)}, y^{(i)})$ 的值都是已知的，所以(式2)其实是参数 $\\mathrm{w}$ 的函数。\n\n$$\n\\begin{aligned}\n    E &= \\frac{1}{2} \\sum \\limits_{i=0}^{n} (y^{(i)} - \\bar{y}^{(i)})^2 &\\pod{8} \\\\\n    &= \\frac{1}{2} \\sum \\limits_{i=0}^{n} (y^{(i)} - \\mathrm{w}^T\\mathrm{x}^{(i)})^2 &\\pod{9}\n\\end{aligned}\n$$\n\n由此可见，模型的训练，实际上就是求取到合适的 $\\mathrm{w}$ ，使(式2)取得最小值。这在数学上称作 **优化问题** ，而 $E(\\mathrm{w})$ 就是我们优化的目标，称之为 **目标函数** 。\n\n### 梯度下降优化算法\n\n大学时我们学过怎样求函数的极值。函数 $y= f(x)$ 的极值点，就是它的导数 $f'(x) = 0$ 的那个点。因此我们可以通过解方程 $f'(x) = 0$ ，求得函数的极值点 $(x_0, y_0)$ 。\n\n不过对于计算机来说，它可不会解方程。但是它可以凭借强大的计算能力，一步一步的去把函数的极值点『试』出来。如下图所示：\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-46acc2c2d52fc366.png)\n\n首先，我们随便选择一个点开始，比如上图的 $x_0$ 点。接下来，每次迭代修改 $x$ 为 $x_1, x_2, x_3, \\dots$ ，经过数次迭代后最终达到函数最小值点。\n\n你可能要问了，为啥每次修改 $x$ 的值，都能往函数最小值那个方向前进呢？这里的奥秘在于，我们每次都是向函数 $y = f(x)$ 的 **梯度** 的 **相反方向** 来修改 $x$ 。什么是 **梯度** 呢？翻开大学高数课的课本，我们会发现 **梯度** 是一个向量，它指向 **函数值上升最快** 的方向。显然，梯度的反方向当然就是函数值下降最快的方向了。我们每次沿着梯度相反方向去修改 $x$ 的值，当然就能走到函数的最小值附近。之所以是最小值附近而不是最小值那个点，是因为我们每次移动的步长不会那么恰到好处，有可能最后一次迭代走远了越过了最小值那个点。步长的选择是门手艺，如果选择小了，那么就会迭代很多轮才能走到最小值附近；如果选择大了，那可能就会越过最小值很远，收敛不到一个好的点上。\n\n按照上面的讨论，我们就可以写出梯度下降算法的公式\n\n$$\nx_{new} = x_{old} - \\eta \\nabla f(x)\n$$\n\n其中， $\\nabla$ 是 **梯度算子** ， $\\nabla f(x)$ 就是指的 $f(x) 梯度。 $\\eta$ 是步长，也称作 **学习速率** 。\n\n对于上一节列出的目标函数(式2)\n\n$$\nE(\\mathrm{w}) = \\frac{1}{2} \\sum \\limits_{i=1}^{n} (y^{i} - \\bar{y}^{(i)})^2\n$$\n\n梯度下降算法可以写成\n\n$$\n\\mathrm{w}_{new} = \\mathrm{w}_{old} - \\eta \\nabla E(\\mathrm{w})\n$$\n\n聪明的你应该能想到，如果要求目标函数的 **最大值** ，那么我们就应该用梯度上升算法，它的参数修改规则是\n\n$$\n\\mathrm{w}_{new} = \\mathrm{w}_{old} + \\eta \\nabla E(\\mathrm{w})\n$$\n\n下面，请先做几次深呼吸，让你的大脑补充足够的新鲜的氧气，我们要来求取 $\\nabla E(\\mathrm{w})$ ，然后带入上式，就能得到线性单元的参数修改规则。\n\n关于 $\\nabla E(\\mathrm{w})$ 的推导过程，我单独把它们放到一节中。您既可以选择慢慢看，也可以选择无视。在这里，您只需要知道，经过一大串推导，目标函数 $E(\\mathrm{w})$ 的梯度是\n\n$$\n\\nabla E(\\mathrm{w}) = - \\sum \\limits_{i=1}^{n} (y^{(i)} - \\bar{y}^{(i)}) \\mathrm{x}^{(i)}\n$$\n\n因此，线性单元的参数修改规则最后是这个样子\n\n$$\n\\mathrm{w}_{new} = \\mathrm{w}_{old} + \\eta \\sum \\limits_{i=1}^{n} (y^{(i)} - \\bar{y}^{(i)}) \\mathrm{x}^{(i)} \\pod{\\text{式3}}\n$$\n\n有了上面这个式子，我们就可以根据它来写出训练线性单元的代码了。\n\n需要说明的是，如果每个样本有M个特征，则上式中的 $\\mathrm{x}, \\mathrm{w}$ 都是M+1维 **向量** (因为我们加上了一个恒为1的虚拟特征 $x_0$，参考前面的内容)，而 $y$ 是 **标量** 。用高逼格的数学符号表示，就是\n\n$$\n\\mathrm{x}, \\mathrm{w} \\in \\mathrm{\\Re}^{M+1} \\\\\ny \\in \\Re^1\n$$\n\n为了让您看明白说的是啥，我吐血写下下面这个解释(写这种公式可累可累了)。因为 $\\mathrm{w}, \\mathrm{x}$ 是M+1维 **列向量** ，所以(式3)可以写成\n\n$$\n\\begin{bmatrix}\n    w_0 \\\\ w_1 \\\\ w_2 \\\\ \\dots \\\\ w_m\n\\end{bmatrix}_{new}\n=\n\\begin{bmatrix}\n    w_0 \\\\ w_1 \\\\ w_2 \\\\ \\dots \\\\ w_m\n\\end{bmatrix}_{old}\n+ \\eta \\sum \\limits_{i=1}^{n} (y^{(i)} - \\bar{y}^{(i)})\n\\begin{bmatrix}\n    1 \\\\ x_{1}^{(i)} \\\\ x_{2}^{(i)} \\\\ \\dots \\\\ x_{m}^{(i)}\n\\end{bmatrix}\n$$\n\n如果您还是没看明白，建议您也吐血再看一下大学时学过的《线性代数》吧。\n\n### $\\nabla E(\\mathrm{w})$ 的推导\n\n这一节你尽可以跳过它，并不太会影响到全文的理解。当然如果你非要弄明白每个细节，那恭喜你骚年，机器学习的未来一定是属于你的。\n\n首先，我们先做一个简单的前戏。我们知道函数的梯度的定义就是它相对于各个变量的 **偏导数** ，所以我们写下下面\n的式子\n\n$$\n\\begin{aligned}\n    \\nabla E(\\mathrm{w})\n    &= \\frac{\\partial}{\\partial \\mathrm{w}} E(\\mathrm{w}) &\\pod{10} \\\\\n    &= \\frac{\\partial}{\\partial \\mathrm{w}} \\frac{1}{2} \\sum \\limits_{i=1}^{n} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{11}\n\n\\end{aligned}\n$$\n\n可接下来怎么办呢？我们知道和的导数等于导数的和，所以我们可以先把求和符号 $\\sum$ 里面的导数求出来，然后再把它们加在一起就行了，也就是\n\n$$\n\\begin{aligned}\n    \\frac{\\partial}{\\partial \\mathrm{w}} \\frac{1}{2} \\sum \\limits_{i=1}^{n} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{12} \\\\\n    = \\frac{1}{2} \\sum \\limits_{i=1}^{n} \\frac{\\partial}{\\partial \\mathrm{w}} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{13}\n\\end{aligned}\n$$\n\n现在我们可以不管高大上的 $\\sum$ 了，先专心把里面的导数求出来。\n\n$$\n\\begin{aligned}\n    \\frac{\\partial}{\\partial \\mathrm{w}} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{14} \\\\\n    = \\frac{\\partial}{\\partial \\mathrm{w}} (y^{(i)2} - 2\\bar{y}^{(i)} y^{(i)} + \\bar{y}^{(i)2}) &\\pod{15}\n\\end{aligned}\n$$\n\n我们知道， $y$ 是与 $\\mathrm{w}$ 无关的常数，而 $\\bar{y} = \\mathrm{w}^T \\mathrm{x}$ ，下面我们根据链式求导法则来求导(上大学时好像叫复合函数求导法则)\n\n$$\n\\frac{\\partial E(\\mathrm{w})}{\\partial \\mathrm{w}} = \\frac{\\partial E(\\bar{y})}{\\partial \\bar{y}} \\frac{\\partial \\bar{y}}{\\partial \\mathrm{w}}\n$$\n\n我们分别计算上式等号右边的两个偏导数\n\n$$\n\\begin{aligned}\n    \\frac{\\partial E(\\mathrm{w})}{\\partial \\bar{y}}\n    &= \\frac{\\partial}{\\partial \\bar{y}} (y^{(i)2} - 2\\bar{y}^{(i)} y^{(i)} + \\bar{y}^{(i)2}) &\\pod{16} \\\\\n    &= -2y^{(i)} + 2\\bar{y}^{(i)} &\\pod{17}\n\\end{aligned}\n$$\n\n>注: 此处原文应该是作者公式错误多写了一个方程编号, 不影响后续, 移除编号 **(18)**\n\n$$\n\\begin{aligned}\n    \\frac{\\partial \\bar{y}}{\\partial \\mathrm{w}}\n    &= \\frac{\\partial}{\\partial \\mathrm{w}} \\mathrm{w}^T \\mathrm{x} &\\pod{19} \\\\\n    &= \\mathrm{x} &\\pod{20}\n\\end{aligned}\n$$\n\n代入，我们求得 $\\sum$ 里面的偏导数是\n\n$$\n\\begin{aligned}\n    \\frac{\\partial}{\\partial \\mathrm{w}} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{21} \\\\\n    = 2(-y^{(i) + \\bar{y}^{(i)}})\\mathrm{x} &\\pod{22}\n\\end{aligned}\n$$\n\n最后代入 $\\nabla E(\\mathrm{w})$ ，求得\n\n$$\n\\begin{aligned}\n    \\nabla E(\\mathrm{w})\n    &= \\frac{1}{2} \\sum \\limits_{i=1}^{n} \\frac{\\partial}{\\partial \\mathrm{w}} (y^{(i)} -\\bar{y}^{(i)})^2 &\\pod{23} \\\\\n    &= \\frac{1}{2} \\sum \\limits_{i=1}^{n} \\frac{\\partial}{\\partial \\mathrm{w}} 2(-y^{(i)} +\\bar{y}^{(i)}) \\mathrm{x} &\\pod{24} \\\\\n    &= - \\sum \\limits_{i=1}^{n} (y^{(i)} - \\bar{y}^{(i)}) \\mathrm{x} &\\pod{25}\n\\end{aligned}\n$$\n\n至此，大功告成。\n\n### 随机梯度下降算法(Stochastic Gradient Descent, SGD)\n\n如果我们根据(式3)来训练模型，那么我们每次更新 $\\mathrm{w}$ 的迭代，要遍历训练数据中所有的样本进行计算，我们称这种算法叫做 **批梯度下降(Batch Gradient Descent)** 。如果我们的样本非常大，比如数百万到数亿，那么计算量异常巨大。因此，实用的算法是SGD算法。在SGD算法中，每次更新 $\\mathrm{w}$ 的迭代，只计算一个样本。这样对于一个具有数百万样本的训练数据，完成一次遍历就会对 $\\mathrm{w}$ 更新数百万次，效率大大提升。由于样本的噪音和随机性，每次更新 $\\mathrm{w}$ 并不一定按照减少 $E$ 的方向。然而，虽然存在一定随机性，大量的更新总体上沿着减少 $E$ 的方向前进的，因此最后也能收敛到最小值附近。下图展示了SGD和BGD的区别\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-3152002d503d768e.png)\n\n如上图，椭圆表示的是函数值的等高线，椭圆中心是函数的最小值点。红色是BGD的逼近曲线，而紫色是SGD的逼近曲线。我们可以看到BGD是一直向着最低点前进的，而SGD明显躁动了许多，但总体上仍然是向最低点逼近的。\n\n最后需要说明的是，SGD不仅仅效率高，而且随机性有时候反而是好事。今天的目标函数是一个『凸函数』，沿着梯度反方向就能找到全局唯一的最小值。然而对于非凸函数来说，存在许多局部最小值。随机性有助于我们逃离某些很糟糕的局部最小值，从而获得一个更好的模型。\n\n## 实现线性单元\n\n>完整代码请参考GitHub: https://github.com/hanbt/learn_dl/blob/master/linear_unit.py (python2.7)\n\n接下来，让我们撸一把代码。\n\n因为我们已经写了感知器的代码，因此我们先比较一下感知器模型和线性单元模型，看看哪些代码能够复用。\n\n| **算法** | **感知器** | **线性单元** |\n| ----- | ----- | --- |\n| 模型 $h(x)$ | $y=f(\\mathrm{w}^T \\mathrm{x})$ | $y=f(\\mathrm{w}^T \\mathrm{x})$ |\n||$f(z)=\\begin{cases} 1 \\quad z \\gt 0 \\\\ 0 \\quad otherwise \\end{cases}$| $f(z)=z$ |\n| 训练规则 | $\\mathrm{w} \\leftarrow \\mathrm{w} + \\eta (y-\\bar{y})\\mathrm{x}$ | $\\mathrm{w} \\leftarrow \\mathrm{w} + \\eta (y-\\bar{y})\\mathrm{x}$ |\n\n比较的结果令人震惊，原来除了激活函数不同之外，两者的模型和训练规则是一样的(在上表中，线性单元的优化算法是SGD算法)。那么，我们只需要把感知器的激活函数进行替换即可。感知器的代码请参考上一篇文章[零基础入门深度学习(1) - 感知器](/2019/05/01/deeplearning-quickstart-1/)，这里就不再重复了。对于一个养成良好习惯的程序员来说，重复代码是不可忍受的。大家应该把代码保存在一个代码库中(比如git)。\n\n```python\nfrom perceptron import Perceptron\n#定义激活函数f\nf = lambda x: x\nclass LinearUnit(Perceptron):\n    def __init__(self, input_num):\n        '''初始化线性单元，设置输入参数的个数'''\n        Perceptron.__init__(self, input_num, f)\n```\n\n通过继承Perceptron，我们仅用几行代码就实现了线性单元。这再次证明了面向对象编程范式的强大。\n\n接下来，我们用简单的数据进行一下测试。\n\n```python\ndef get_training_dataset():\n    '''\n    捏造5个人的收入数据\n    '''\n    # 构建训练数据\n    # 输入向量列表，每一项是工作年限\n    input_vecs = [[5], [3], [8], [1.4], [10.1]]\n    # 期望的输出列表，月薪，注意要与输入一一对应\n    labels = [5500, 2300, 7600, 1800, 11400]\n    return input_vecs, labels    \ndef train_linear_unit():\n    '''\n    使用数据训练线性单元\n    '''\n    # 创建感知器，输入参数的特征数为1（工作年限）\n    lu = LinearUnit(1)\n    # 训练，迭代10轮, 学习速率为0.01\n    input_vecs, labels = get_training_dataset()\n    lu.train(input_vecs, labels, 10, 0.01)\n    #返回训练好的线性单元\n    return lu\nif __name__ == '__main__': \n    '''训练线性单元'''\n    linear_unit = train_linear_unit()\n    # 打印训练获得的权重\n    print linear_unit\n    # 测试\n    print 'Work 3.4 years, monthly salary = %.2f' % linear_unit.predict([3.4])\n    print 'Work 15 years, monthly salary = %.2f' % linear_unit.predict([15])\n    print 'Work 1.5 years, monthly salary = %.2f' % linear_unit.predict([1.5])\n    print 'Work 6.3 years, monthly salary = %.2f' % linear_unit.predict([6.3])\n```\n\n程序运行结果如下图\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-92f00082e3db32d2.png)\n\n拟合的直线如下图\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-b2db886ef2f18771.png)\n\n## 小结\n\n事实上，一个机器学习算法其实只有两部分\n\n- *模型* 从输入特征 $\\mathrm{x}$ 预测输入 $y$ 的那个函数 $h(x)$\n- *目标函数* 目标函数取最小(最大)值时所对应的参数值，就是模型的参数的 **最优值** 。很多时候我们只能获得目标函数的 **局部最小(最大)值** ，因此也只能得到模型参数的局部最优值。\n\n因此，如果你想最简洁的介绍一个算法，列出这两个函数就行了。\n\n接下来，你会用 **优化算法** 去求取目标函数的最小(最大)值。**[随机]梯度{下降|上升}** 算法就是一个 **优化算法** 。针对同一个目标函数，不同的 **优化算法** 会推导出不同的训练规则。我们后面还会讲其它的优化算法。\n\n其实在机器学习中，算法往往并不是关键，真正的关键之处在于选取特征。选取特征需要我们人类对问题的深刻理解，经验、以及思考。而 **神经网络** 算法的一个优势，就在于它能够自动学习到应该提取什么特征，从而使算法不再那么依赖人类，而这也是神经网络之所以吸引人的一个方面。\n\n现在，经过漫长的烧脑，你已经具备了学习 **神经网络** 的必备知识。下一篇文章，我们将介绍本系列文章的主角： **神经网络** ，以及用来训练神经网络的大名鼎鼎的算法： **反向传播** 算法。至于现在，我们应该暂时忘记一切，尽情奖励自己一下吧。\n\n> 注: 去掉原作者爱吃的红烧肉 ->_->\n\n## 参考资料\n\n1. Tom M. Mitchell, \"机器学习\", 曾华军等译, 机械工业出版社","tags":["深度学习入门"],"categories":["转载"]},{"title":"零基础入门深度学习 - Menu","url":"%2F2019%2F05%2F01%2Fdeeplearning-quickstart-menu%2F","content":"\n> 本系列文章全文转载自作业部落 [@hanbingtao](https://www.zybuluo.com/hanbingtao/note/433855) 老师的零基础入门系列文章.\n由于作业部落没有很好的索引相关功能, 转载于个人博客, 重新做了排版工作, 版权归原作者所有.\n\n## 文章列表\n\n-  <a href=\"/2019/05/01/deeplearning-quickstart-1/\" target=\"_blank\">零基础入门深度学习(1) - 感知器</a>\n\n-  <a href=\"/2019/05/03/deeplearning-quickstart-2/\" target=\"_blank\">零基础入门深度学习(2) - 线性单元和梯度下降</a>\n\n-  <a href=\"/2019/05/08/deeplearning-quickstart-3/\" target=\"_blank\">零基础入门深度学习(3) - 神经网络和反向传播算法</a>\n\n- 零基础入门深度学习(4) - 卷积神经网络\n\n- 零基础入门深度学习(5) - 循环神经网络\n\n- 零基础入门深度学习(6) - 长短时记忆网络(LSTM)\n\n- 零基础入门深度学习(7) - 递归神经网络\n\n","tags":["深度学习入门"]},{"title":"转载 - 零基础入门深度学习(1) - 感知器","url":"%2F2019%2F05%2F01%2Fdeeplearning-quickstart-1%2F","content":"\n![](/static/upload-images.jianshu.io/upload_images/2256672-06627c71f0d8c0dc.jpg)\n\n> 无论即将到来的是大数据时代还是人工智能时代，亦或是传统行业使用人工智能在云上处理大数据的时代，作为一个有理想有追求的程序员，不懂深度学习（Deep Learning）这个超热的技术，会不会感觉马上就out了？现在救命稻草来了，《零基础入门深度学习》系列文章旨在讲帮助爱编程的你从零基础达到入门级水平。零基础意味着你不需要太多的数学知识，只要会写程序就行了，没错，这是专门为程序员写的文章。虽然文中会有很多公式你也许看不懂，但同时也会有更多的代码，程序员的你一定能看懂的（我周围是一群狂热的Clean Code程序员，所以我写的代码也不会很差）。\n\n## 深度学习是啥\n\n在人工智能领域，有一个方法叫机器学习。在机器学习这个方法里，有一类算法叫神经网络。神经网络如下图所示：\n\n<!-- more -->\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-c6f640c11a06ac2e.png)\n\n上图中每个圆圈都是一个神经元，每条线表示神经元之间的连接。我们可以看到，上面的神经元被分成了多层，层与层之间的神经元有连接，而层内之间的神经元没有连接。最左边的层叫做 **输入层** ，这层负责接收输入数据；最右边的层叫 **输出层** ，我们可以从这层获取神经网络输出数据。输入层和输出层之间的层叫做 **隐藏层** 。\n\n隐藏层比较多（大于2）的神经网络叫做深度神经网络。而深度学习，就是使用深层架构（比如，深度神经网络）的机器学习方法。\n\n那么深层网络和浅层网络相比有什么优势呢？简单来说深层网络能够表达力更强。事实上，一个仅有一个隐藏层的神经网络就能拟合任何一个函数，但是它需要很多很多的神经元。而深层网络用少得多的神经元就能拟合同样的函数。也就是为了拟合一个函数，要么使用一个浅而宽的网络，要么使用一个深而窄的网络。而后者往往更节约资源。\n\n深层网络也有劣势，就是它不太容易训练。简单的说，你需要大量的数据，很多的技巧才能训练好一个深层网络。这是个手艺活。\n\n## 感知器\n\n看到这里，如果你还是一头雾水，那也是很正常的。为了理解神经网络，我们应该先理解神经网络的组成单元—— **神经元** 。神经元也叫做 **感知器** 。感知器算法在上个世纪50-70年代很流行，也成功解决了很多问题。并且，感知器算法也是非常简单的。\n\n### 感知器的定义\n\n下图是一个感知器：\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-801d65e79bfc3162.png)\n\n可以看到，一个感知器有如下组成部分：\n\n- **输入权值** 一个感知器可以接收多个输入 $(x_1, x_2, \\dots, x_n | x_i \\in \\Re)$，每个输入上有一个 **权值** $w_i \\in \\Re$，此外还有一个 **偏置项** $b \\in \\Re$ ，就是上图中的 $w_0$ 。\n\n- **激活函数** 感知器的激活函数可以有很多选择，比如我们可以选择下面这个**阶跃函数** $f$ 来作为激活函数：\n\n$$\nf(z)=\\begin{cases}\n    1 \\quad z\\gt 0 \\\\\n    \\\\\n    0 \\quad othercase \\\\\n\\end{cases} \\tag{1}\n$$\n\n- **输出** 感知器的输出由下面这个公式来计算\n\n$$\n    y = f(w \\bullet x + b) \\tag{公式1}\n$$\n\n如果看完上面的公式一下子就晕了，不要紧，我们用一个简单的例子来帮助理解。\n\n#### 例子：用感知器实现`and`函数\n\n我们设计一个感知器，让它来实现`and`运算。程序员都知道，`and`是一个二元函数（带有两个参数 $x_1$ 和 $x_2$），下面是它的 **真值表**：\n\n| $x_1$ | $x_2$ | $y$ |\n| ----- | ----- | --- |\n|0|0|0|\n|0|1|0|\n|1|0|0|\n|1|1|1|\n\n为了计算方便，我们用0表示 **false** ，用1表示 **true** 。这没什么难理解的，对于C语言程序员来说，这是天经地义的。\n\n我们令 $w_1 = 0.5; w_2 = 0.5; b = -0.8$，而激活函数 $f$ 就是前面写出来的 **阶跃函数** ，这时，感知器就相当于`and`函数。不明白？我们验算一下：\n\n输入上面真值表的第一行，即$x_1 = 0; x_2 = 0$，那么根据公式(1)，计算输出： \n\n$$\n\\begin{aligned}\n    y &= f(w \\bullet x + b) &\\pod{2} \\\\\n    &= f(w_1 x_1 + w_2 x_2 + b ) &\\pod{3} \\\\\n    &= f(0.5 \\times 0 + 0.5 \\times 0 - 0.8) &\\pod{4} \\\\\n    &= f(-0.8) &\\pod{5} \\\\\n    &= 0 &\\pod{6}\n\\end{aligned}\n$$\n\n也就是当 $x_1 x_2$ 都为0的时候，$y$ 为0，这就是 **真值表** 的第一行。读者可以自行验证上述真值表的第二、三、四行。\n\n#### 例子：用感知器实现`or`函数\n\n同样，我们也可以用感知器来实现`or`运算。仅仅需要把偏置项 $b$ 的值设置为-0.3就可以了。我们验算一下，下面是`or`运算的 **真值表** ：\n\n| $x_1$ | $x_2$ | $y$ |\n| ----- | ----- | --- |\n|0|0|0|\n|0|1|1|\n|1|0|1|\n|1|1|1|\n\n我们来验算第二行，这时的输入是 $x_1 = 0; x_2 = 1$ ，带入公式(1)：\n\n$$\n\\begin{aligned}\n    y &= f(w \\bullet x + b) &\\pod{7} \\\\\n    &= f(w_1 x_1 + w_2 x_2 + b ) &\\pod{8} \\\\\n    &= f(0.5 \\times 0 + 0.5 \\times 1 - 0.3) &\\pod{9} \\\\\n    &= f(0.2) &\\pod{10} \\\\\n    &= 1 &\\pod{11}\n\\end{aligned}\n$$\n\n也就是当 $x_1 = 0; x_2 = 1$ 时， $y$ 为1，即`or` **真值表** 第二行。读者可以自行验证其它行。\n\n### 感知器还能做什么\n\n事实上，感知器不仅仅能实现简单的布尔运算。它可以拟合任何的线性函数，任何 **线性分类** 或 **线性回归** 问题都可以用感知器来解决。前面的布尔运算可以看作是 **二分类** 问题，即给定一个输入，输出0（属于分类0）或1（属于分类1）。如下面所示，`and`运算是一个线性分类问题，即可以用一条直线把分类0（false，红叉表示）和分类1（true，绿点表示）分开。\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-acff576747ef4259.png)\n\n然而，感知器却不能实现异或运算，如下图所示，异或运算不是线性的，你无法用一条直线把分类0和分类1分开。\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-9b651d237936781c.png)\n\n### 感知器的训练\n\n现在，你可能困惑前面的权重项和偏置项的值是如何获得的呢？这就要用到感知器训练算法：将权重项和偏置项初始化为0，然后，利用下面的 **感知器规则** 迭代的修改 $w_i$ 和 $b$ ，直到训练完成。\n\n$$\n\\begin{aligned}\n    w_i &\\gets w_i + \\Delta w_i  &\\pod{12} \\\\\n    b &\\gets b + \\Delta b  &\\pod{13}\n\\end{aligned}\n$$\n\n其中: \n\n$$\n\\begin{aligned}\n    \\Delta w_i &= \\eta(t-y)x_i  &\\pod{14} \\\\\n    \\Delta b &= \\eta(t-y)  &\\pod{15}\n\\end{aligned}\n$$\n\n $w_i$ 是与输入 $x_i$ 对应的权重项， $b$ 是偏置项。事实上，可以把 $b$ 看作是值永远为1的输入 $x_b$ 所对应的权重。 $t$ 是训练样本的`实际值`，一般称之为`label`。而是 $y$ 感知器的输出值，它是根据 **公式(1)** 计算得出。 $\\eta$ 是一个称为 **学习速率** 的常数，其作用是控制每一步调整权的幅度。\n\n每次从训练数据中取出一个样本的输入向量 $\\mathrm{x}$ ，使用感知器计算其输出 $y$，再根据上面的规则来调整权重。每处理一个样本就调整一次权重。经过多轮迭代后（即全部的训练数据被反复处理多轮），就可以训练出感知器的权重，使之实现目标函数。\n\n#### 编程实战：实现感知器\n\n> 完整代码请参考GitHub: https://github.com/hanbt/learn_dl/blob/master/perceptron.py (python2.7)\n\n对于程序员来说，没有什么比亲自动手实现学得更快了，而且，很多时候一行代码抵得上千言万语。接下来我们就将实现一个感知器。\n\n下面是一些说明：\n\n- 使用python语言。python在机器学习领域用的很广泛，而且，写python程序真的很轻松。\n- 面向对象编程。面向对象是特别好的管理复杂度的工具，应对复杂问题时，用面向对象设计方法很容易将复杂问题拆解为多个简单问题，从而解救我们的大脑。\n- 没有使用numpy。numpy实现了很多基础算法，对于实现机器学习算法来说是个必备的工具。但为了降低读者理解的难度，下面的代码只用到了基本的python（省去您去学习numpy的时间）。\n\n下面是感知器类的实现，非常简单。去掉注释只有27行，而且还包括为了美观（每行不超过60个字符）而增加的很多换行。\n\n```python\nclass Perceptron(object):\n    def __init__(self, input_num, activator):\n        '''\n        初始化感知器，设置输入参数的个数，以及激活函数。\n        激活函数的类型为double -> double\n        '''\n        self.activator = activator\n        # 权重向量初始化为0\n        self.weights = [0.0 for _ in range(input_num)]\n        # 偏置项初始化为0\n        self.bias = 0.0\n    def __str__(self):\n        '''\n        打印学习到的权重、偏置项\n        '''\n        return 'weights\\t:%s\\nbias\\t:%f\\n' % (self.weights, self.bias)\n    def predict(self, input_vec):\n        '''\n        输入向量，输出感知器的计算结果\n        '''\n        # 把input_vec[x1,x2,x3...]和weights[w1,w2,w3,...]打包在一起\n        # 变成[(x1,w1),(x2,w2),(x3,w3),...]\n        # 然后利用map函数计算[x1*w1, x2*w2, x3*w3]\n        # 最后利用reduce求和\n        return self.activator(\n            reduce(lambda a, b: a + b,\n                   map(lambda (x, w): x * w,  \n                       zip(input_vec, self.weights))\n                , 0.0) + self.bias)\n    def train(self, input_vecs, labels, iteration, rate):\n        '''\n        输入训练数据：一组向量、与每个向量对应的label；以及训练轮数、学习率\n        '''\n        for i in range(iteration):\n            self._one_iteration(input_vecs, labels, rate)\n    def _one_iteration(self, input_vecs, labels, rate):\n        '''\n        一次迭代，把所有的训练数据过一遍\n        '''\n        # 把输入和输出打包在一起，成为样本的列表[(input_vec, label), ...]\n        # 而每个训练样本是(input_vec, label)\n        samples = zip(input_vecs, labels)\n        # 对每个样本，按照感知器规则更新权重\n        for (input_vec, label) in samples:\n            # 计算感知器在当前权重下的输出\n            output = self.predict(input_vec)\n            # 更新权重\n            self._update_weights(input_vec, output, label, rate)\n    def _update_weights(self, input_vec, output, label, rate):\n        '''\n        按照感知器规则更新权重\n        '''\n        # 把input_vec[x1,x2,x3,...]和weights[w1,w2,w3,...]打包在一起\n        # 变成[(x1,w1),(x2,w2),(x3,w3),...]\n        # 然后利用感知器规则更新权重\n        delta = label - output\n        self.weights = map(\n            lambda (x, w): w + rate * delta * x,\n            zip(input_vec, self.weights))\n        # 更新bias\n        self.bias += rate * delta\n```\n\n接下来，我们利用这个感知器类去实现`and`函数。\n\n```python\ndef f(x):\n    '''\n    定义激活函数f\n    '''\n    return 1 if x > 0 else 0\ndef get_training_dataset():\n    '''\n    基于and真值表构建训练数据\n    '''\n    # 构建训练数据\n    # 输入向量列表\n    input_vecs = [[1,1], [0,0], [1,0], [0,1]]\n    # 期望的输出列表，注意要与输入一一对应\n    # [1,1] -> 1, [0,0] -> 0, [1,0] -> 0, [0,1] -> 0\n    labels = [1, 0, 0, 0]\n    return input_vecs, labels    \ndef train_and_perceptron():\n    '''\n    使用and真值表训练感知器\n    '''\n    # 创建感知器，输入参数个数为2（因为and是二元函数），激活函数为f\n    p = Perceptron(2, f)\n    # 训练，迭代10轮, 学习速率为0.1\n    input_vecs, labels = get_training_dataset()\n    p.train(input_vecs, labels, 10, 0.1)\n    #返回训练好的感知器\n    return p\nif __name__ == '__main__': \n    # 训练and感知器\n    and_perception = train_and_perceptron()\n    # 打印训练获得的权重\n    print and_perception\n    # 测试\n    print '1 and 1 = %d' % and_perception.predict([1, 1])\n    print '0 and 0 = %d' % and_perception.predict([0, 0])\n    print '1 and 0 = %d' % and_perception.predict([1, 0])\n    print '0 and 1 = %d' % and_perception.predict([0, 1])\n```\n\n将上述程序保存为perceptron.py文件，通过命令行执行这个程序，其运行结果为：\n\n![](/static/upload-images.jianshu.io/upload_images/2256672-1e66158656366b57.png)\n\n神奇吧！感知器竟然完全实现了`and`函数。读者可以尝试一下利用感知器实现其它函数。\n\n## 小结\n终于看（写）到小结了...，大家都累了。对于零基础的你来说，走到这里应该已经很烧脑了吧。没关系，休息一下。值得高兴的是，你终于已经走出了深度学习入门的第一步，这是巨大的进步；坏消息是，这仅仅是最简单的部分，后面还有无数艰难险阻等着你。不过，你学的困难往往意味着别人学的也困难，掌握一门高门槛的技艺，进可糊口退可装逼，是很值得的。\n\n下一篇文章，我们将讨论另外一种感知器： **线性单元** ，并由此引出一种可能是最最重要的优化算法： **梯度下降** 算法。\n\n## 参考资料\n\n1. Tom M. Mitchell, \"机器学习\", 曾华军等译, 机械工业出版社\n","tags":["深度学习入门"],"categories":["转载"]},{"title":"解决 \"Failed to Initialize NVML: Driver/library Version Mismatch\"","url":"%2F2019%2F04%2F24%2Fresolve-NVML-driver-version-mismatch%2F","content":"\n服务器更新 `nvidia driver` 后遇到以下问题:\n\n`Failed to initialize NVML: Driver/library version mismatch`\n\n## 一句话解决方案:\n\n```bash\n    # su 权限\n    lsmod | grep -i ^nvidia | awk '{print $1}' | rmmod && nvidia-smi\n```\n\n或者\n\n```bash\n    # 雾\n    sudo reboot\n```\n\n## 原因分析:\n\n驱动更新后 linux 内核对应驱动的 kernel module 并没有重置, 外部相关进程引用了旧版本驱动相关的 mod, 需要手动卸载, 重新执行 `nvidia-smi`\n会自动加载新版本 mod 到内核\n\n## 注意\n\n卸载过程可能会因为相关进程引用或者内核 mod 引用顺序导致卸载失败, 这时需要按照提示顺序卸载.\n\n<!-- more -->\n\n比如:\n\n```bash\n    rmmod nvidia\n    > rmmod: ERROR: Module nvidia is in use by: nvidia_modeset nvidia_uvm\n```\n\n这时就需要先卸载`nvidia_modeset` 和 `nvidia_uvm`\n\n一些相关的 `kernel mod` 命令\n\n* 查看进程引用 `mod`\n\n```bash\n    lsof -n -w /dev/nvidia\n```\n\n* kernel mod 卸载\n\n```bash\n    rmmod <module_name> | modprobe -r <module_name>\n```\n\n* kernel mod 加载\n\n```bash\n    modprobe\n```\n \n\n## 参考资料\n\n- [stackoverflow](https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch)\n- [Comzyh的博客](https://comzyh.com/blog/archives/967/)\n- [archlinux](https://wiki.archlinux.org/index.php/Kernel_module)\n","tags":["nvidia"]},{"title":"支持 GPU 调度的 Kubernetes 部署方案(CentOS)","url":"%2F2019%2F04%2F16%2Finstall-k8s-cluster-with-gpu-support%2F","content":"## docker installation\n\n- optional: clean old version if needed\n```\nsudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine \\\n                  docker-ce \\\n                  docker-ce-cli \\\n                  containerd.io\n```\n\n- install yum utils\n```\nsudo yum install -y yum-utils device-mapper-persistent-data lvm2\n```\n\n- add docker-ce repo\n```\nsudo yum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n<!-- more -->\n\n- install docker-ce\n```\nsudo yum install docker-ce docker-ce-cli containerd.io\n```\n\n- optional: setup docker `data-root`\n\n`dockerd` store `images/caches/volumes ...` data in `/var/lib/docker` by default, and the `kuberntes` will GC docker\nimage NOT CURRENT IN USING, change the `data-root` to a large disk portion.\n\n```\nsudo vi /usr/lib/systemd/system/docker.service\n\n> append --data-root <a large disk portion> behind dockerd Exec\n```\n\n## nvidia-docker | nvidia-container-runtime installation\n\n- add nvidia-docker repo\n```\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \\\n  sudo tee /etc/yum.repos.d/nvidia-docker.repo\n```\n\n- install nvidia-docker\n```\nsudo yum install nvidia-docker2\nsudo pkill -SIGHUP dockerd\n```\n\n- modify `/etc/docker/daemon.json` to enable `nvidia` as default docker runtime\n\n- optional: setup your own `shadowsocks server & client & privoxy`\n\n- modify `/usr/lib/systemd/system/docker.server` to enable docker image pull access to `gcr.io`\n\n```\nEnvironment=\"HTTP_PROXY=x.x.x.x:xx;HTTPS_PROXY=x.x.x.x:xx;NO_PROXY=x.x.x.x:xx\"\n```\n\n## kubernetes stack installation (local kubelet)\n\n- optional: remove outdated kubeadm, kubelet, kubectl\n\n```\nsudo yum remove -y kubeadm kubelet kubectl\n```\n\n- `kubelet`, `kubectl`, `kubeadm` install\n    >follow [here](https://kubernetes.io/docs/setup/independent/install-kubeadm/)\n\n- using `kubeadm` to install `HA` cluster\n    >follow [here](https://kubernetes.io/docs/setup/independent/setup-ha-etcd-with-kubeadm/)\n\n## kubernetes stack installation (rke -> stack in docker)\n\n- install [rke](https://github.com/rancher/rke)\n\n- rke up\n\n```yaml\n\nnodes:\n    - address: 192.168.1.14\n      user: jinyi\n      role:\n        - controlplane\n        - etcd\n        - worker\n    - address: 192.168.1.15\n      user: jinyi\n      role:\n        - controlplane\n        - etcd\n        - worker\n    - address: 192.168.1.16\n      user: jinyi\n      role:\n        - controlplane\n        - etcd\n        - worker\n\n```\n\n- more config [here](https://rancher.com/docs/rke/latest/en/)\n\n## apply services & conf to cluster\n\n### kubernetes-dashboard\n\n- apply stable `kubernetes-dashboard`\n\n```bash\n    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\n```\n\n- create `admin role binding` (local only for security)\n\n```bash\necho `\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n` | kubectl apply -f -\n```\n\n- get `dashboard login token` & login to dashboard\n\n```bash\n    kubectl -n kube-system describe secrets admin-user | grep token:\n    \n    # copy the output token to clipboard\n    \n    # start local proxy\n    kubectl proxy\n    \n    # open in bro\n```\n\n- open in browser [kubernetes-dashboard](http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/)\n\n- enter `token` you copy before & login\n","tags":["linux"]},{"title":"Css中清除浮动的几种方式","url":"%2F2016%2F10%2F26%2Fclear-float-of-ul%2F","content":"\n前端使用 `ul > li` + `float` 方式生成一个 `navbar` 是一种常见的页面展示手段, 但是浮动之后会导致`ul`高度无法正常撑起, 所以需要清除浮动以正常撑起父元素高度. 这里介绍几种常见的浮动清除的方式.\n\n```html\n    <ul>\n        <li></li>\n        <li></li>\n        <li></li>\n        <li></li>\n    </ul>\n```\n\n```css\n    ul {\n        margin: 0 0;\n        padding: 0 0;\n        list-style-type: none;\n    }\n\n    li {\n        float: right;\n        width: 80px;\n        height: 40px;\n        margin-right: 5%;\n        margin-bottom: 10px;\n        line-height: 40px;\n        text-align: center;\n    }\n```\n\n<!-- more -->\n\n### 给ul添加高度\n\n    这个是最直接的方法, 给`ul`元素添加一个高度\n\n    ```css\n        ul {\n            height: 40px;\n        }\n    ```\n\n### 给最后一个li后添加一个 **空的** `div`, 给`div`添加`clear: both`样式\n\n    ```html\n        <li>\n        </li>\n        <div style=\"clear:both;\"></div>\n    ```\n\n### 给ul添加`overflow: hidden; zoom: 1`样式\n\n    ```css\n        ul {\n            overflow: hidden;\n            zoom: 1;\n        }\n    ```\n\n### 使用 ul **伪类** 进行浮动清除, 对`ul`添加`class=\"clearfix\"`\n\n    ```css\n        .clearfix {\n            *zoom: 1;\n        }\n        .clearfix:before, .clearfix:after {\n            display: table;\n            line-height: 0;\n            content: \"\";\n        }\n        .clearfix:after {\n            clear: both;\n        }\n    ```\n\n#### 参考链接\n* [推酷](http://www.tuicool.com/articles/3iuaMzn)\n","tags":["浮动"]},{"title":"Nodejs版本更新记录","url":"%2F2016%2F10%2F19%2Fnodejs-versions-update-mark-md%2F","content":"\nv6今天LTS, 官方pending了半个多月今天终于up了. 记录一下node主要版本更新内容, 方便选择. 关于官方进度及相关版本计划可以参考[这里](https://github.com/nodejs/lts), 看起来现在用`V4` 和 `V6` 是明智的, `V5`还是放弃吧.\n\n## v4.x\n\n```\n    v4 更新\n    1. 模板字符串\n    2. 类语法糖\n    3. 箭头函数\n    4. 对象字面量\n    5. Promise\n    6. 新的字符串方法\n    7. let 和 const\n```\n\n## v6.x\n\n```\n    nodejs更新主要新特性\n    1. 默认函数参数\n    2. 展开操作符\n    3. 解构赋值\n    4. new.target\n    5. Proxy, 原生对象\n    6. Reflect, 原生对象\n    7. Symbol, 原生对象\n```\n\n\n### 参考资料\n* [v4](http://wwsun.github.io/posts/upgrade-to-node-v4.html)\n* [v6](http://www.tuicool.com/articles/bqmiU3q)\n"},{"title":"Linux服务器安全设置","url":"%2F2016%2F03%2F18%2Flinux-server-setting%2F","content":"\n简明的linux服务器安全设置指南, 包括: 公钥登录, 禁止密码登录, 禁用 root 账户等.\n\n公司的阿里云主机常年被 ssh 外加 http 各种扫, 除了一方面写出更加安全, 健壮的代码之外, 另一方面服务器的安全设置也不容忽视.\n下面是我自己常用的服务器端相关配置. 阿里云主机, centOS 6.x.\n\n## 账户设置\n\n添加公共账户, 避免直接使用 root 账户.\n阿里云的主机默认只提供了一个 root 账户, 我们需要添加一个工作账户, 并赋予 root 权限, 避免直接使用 root.\n\n```sh\n    useradd devops         //添加 devops 账户\n    passwd devops          //修改 devops 账户密码\n    useradd -G root devops //添加 devops 到 root 用户组\n```\n\n这样我们就拥有了一个 root 权限的账户, 接下来就是禁止 root 账户的 shell 登录和使用.\n\n<!-- more -->\n由于我们以后不会再使用密码登录, 并且要禁止 root 的 shell 登录. 所以, 在禁用之前, 需要先配置好公钥文件, 防止无法正常登录服务器.\n\n1. 生成密钥(ssh-keygen)\n2. 复制公钥到服务器(ssh-copy-id)\n3. 修改 ssh server 配置文件, 允许公钥认证, sudo vi /etc/ssh/sshd_config\n```\n    RSAAuthentication yes       //开启RSA 及公钥认证\n    PubkeyAuthentication yes\n```\n\n4. 修改服务器端文件夹的拥有者及权限, 权限设置是必须的, 否则不能正常识别公钥\n```sh\n    chown -R devops:devops .ssh         //修改.ssh 文件夹的拥有者\n    chmod 700 .ssh                      //修改文件夹权限为700,必须\n    chmod 600 .ssh/authorized_keys      //修改文件权限为600,必须\n    sudo services sshd restart          //重启 ssh 服务\n```\n\n接下来进行 ssh 登录测试, 如果正常登录且未提示输入密码, 证明我们的公钥配置已经生效, 这个时候就可以大胆的关闭 root 账户登录和账户登录的密码验证了.\nsudo vi /etc/ssh/sshd_config\n\n```sh\n    PermitRootLogin no          //禁止 root 用户登录\n    PasswordAuthentication no   //禁用密码验证\n```\n\n## 端口设置及 iptables\n\n除了做到以上的还不能确保足够的安全, 我们需要对服务器的端口进行限定开放.\n\n我司服务器目前对外开放端口只有80, 443, 22三个端口, 即除了 ssh, http, https 之外, 不对外部开放任何端口.有需要可以修改 ssh 默认端口号, sudo vi /etc/ssh/sshd_config\n```\n    port xx\n```\n\n这个配置可以在阿里云的控制面板内进行设置, 当然本地进行设置也是一样的道理.\n\n由于阿里云的机房内不是一台机器, 也就是说尽管我们的主机没有暴露在外网环境下, 但是阿里云的内网内部还是可以扫描到我们的服务器的.所以,\n我们还需要使用 iptables 对内网 ip 进行限制.\n\n我司在阿里有两台服务器, 分布在同一个内网环境, 所以除了两者之间互访之外, 屏蔽所有其他的内网互访. 这个在阿里云主机的控制面板也是可以设置的, iptables 同理.\n\n## 其他\n\n防火墙保持常开, 定时备份, 磁盘加密, 及时查 ssh 和 http 的相关 log, 发现可疑情况及时处理.\n另, 对于 http 层可以在 nginx 接入层设置 ip 黑名单进行屏蔽.\n","tags":["linux"]},{"title":"Nginx配置访问限制","url":"%2F2016%2F03%2F17%2FNginx-secret-limit-setting%2F","content":"\n使用 ngxin 时添加IP访问控制是常见需求, 最近遇到该需求, 简单记录如下.\n\n## 模块依赖\n nginx 的 IP 访问控制依赖于内置的 `ngx_http_access_module`. 在默认情况下, 这个包在编译中是安装的, 除非编译过程中显示指定`--without ngx_http_access_module`.\n\n## 配置方法\n\n样例配置如下, example.conf\n```nginx\nlocation / {\n    deny  192.168.1.1;\n    allow 192.168.1.0/24;\n    allow 10.1.1.0/16;\n    allow 2001:0db8::/32;\n    deny  all;\n}\n\n```\n\n<!-- more -->\n\n写完之后 include 到配置文件即可\n`include /path/to/your_conf/*.conf;`\nPS: 记得加分号, `;`\n\nnginx 对于匹配顺序有如下规定: 任何一个 IP 地址, 访问了该 location 之后, 则`从上到下`对规则进行匹配, `漏斗`原则~ . ~ .\n举例如下:\n\n- `192.168.1.1`: 进入之后匹配到第一个`IP/IP 段`, 则执行对应的规则 `deny`, 返回.\n- `192.168.1.12`: 进入之后第一个未匹配, 跳过; 匹配到第二个, 执行对应规则 `allow`, 返回.\n- `172.168.1.101`: 进入之后前四个都未匹配到, 匹配最后一个 `all`, 执行 `deny`, 返回.\n\n## 配置语法\n\n```\n    Syntax: (allow|deny) address | CIDR | unix: | all\n    Default: —\n    Context: http, server, location, limit_except\n```\n\n语法设置可以为 `allow|deny` 两个关键字, 后面的对应属性可以为 IP 地址/地址段(可以使ipv4 或者 ipv6), CIRD(见[附1](#tip1)), `unix:`, `all`, 无默认值.\n配置模块可以出现在 nginx 的 `http{}`, `server{}`, `location{}`, `limit_except{}` 模块.\n如果属性值配置为`unix:`, 则会允许或拒绝所有 Unix 域socket.(该选项只在 nginx 1.5.1之后的版本生效)\n\n## 可用的第三方配置模块\n nginx 只提供了简单的静态 IP 控制, 不过在服务端接入层用于做长效黑名单控制已经足够了, 如果针对访问控制进行动态规则调整, 我找到了`这货`\n [ngx_white_black_list](https://github.com/codehunte/ngx_white_black_list/blob/master/white_black_list.txt')\n\n\n简单说到这里, 其实还是挺简单的, 注意理一下匹配规则.\n\n* [附1](#tip1):\n\n`无类别域间路由`\n\n>无类别域间路由（Classless Inter-Domain Routing、CIDR）是一个用于给用户分配IP地址以及在互联网上有效地路由IP数据包的对IP地址进行归类的方法。\n在域名系统出现之后的第一个十年里，基于分类网络进行地址分配和路由IP数据包的设计就已明显显得可扩充性不足 （参见RFC 1517）。为了解决这个问题，互联网工程工作小组在1993年发布了一新系列的标准——RFC 1518和RFC 1519——以定义新的分配IP地址块和路由IPv4数据包的方法。\n一个IP地址包含两部分：标识网络的前缀和紧接着的在这个网络内的主机地址。在之前的分类网络中，IP地址的分配把IP地址的32位按每8位为一段分开。这使得前缀必须为8，16或者24位。因此，可分配的最小的地址块有256（24位前缀，8位主机地址，28=256）个地址，而这对大多数企业来说太少了。大一点的地址块包含65536（16位前缀，16位主机，216=65536）个地址，而这对大公司来说都太多了。这导致不能充分使用IP地址和在路由上的不便，因为大量的需要单独路由的小型网络（C类网络）因在地域上分得很开而很难进行聚合路由，于是给路由设备增加了很多负担。\n\n<\n\n>无类别域间路由是基于可变长子网掩码（VLSM）来进行任意长度的前缀的分配的。在RFC 950（1985）中有关于可变长子网掩码的说明。CIDR包括：\n指定任意长度的前缀的可变长子网掩码技术。遵从CIDR规则的地址有一个后缀说明前缀的位数，例如：192.168.0.0/16。这使得对日益缺乏的IPv4地址的使用更加有效。\n将多个连续的前缀聚合成超网，以及，在互联网中，只要有可能，就显示为一个聚合的网络，因此在总体上可以减少路由表的表项数目。聚合使得互联网的路由表不用分为多级，并通过VLSM逆转“划分子网”的过程。\n根据机构的实际需要和短期预期需要而不是分类网络中所限定的过大或过小的地址块来管理IP地址的分配的过程。\n因为在IPv6中也使用了IPv4的用后缀指示前缀长度的CIDR，所以IPv4中的分类在IPv6中已不再使用。\n\n<\n\n>摘自维基百科: [无类别域间路由]('https://zh.wikipedia.org/wiki/%E6%97%A0%E7%B1%BB%E5%88%AB%E5%9F%9F%E9%97%B4%E8%B7%AF%E7%94%B1')\n","tags":["安全"]},{"title":"2016读书单","url":"%2F2016%2F03%2F10%2F2016-reading-list%2F","content":"\n2016年新年读书计划, 准备深入学习JavaScript 的前端和后端开发, 大致了解一下 web 开发周围的相关知识.\n\n## 网络相关\n  http 协议的深入了解, nginx 开发相关, web 安全相关\n  ```\n    * 图解 http\n    * http 权威指南\n    * 跟我学 Nginx + Lua 开发\n    * Programming in Lua 3ed\n    * 白帽子讲 web 安全\n  ```\n\n## web 前端相关\n  html&css 深入理解, bootstrap 框架, JavaScript 深入学习\n  ```\n    * html5 与 css3 基础教程\n    * css 禅意花园\n    * css 权威指南\n    * 深入理解 bootstrap\n    * JavaScript 高级程序设计(第三版)\n    * JavaScript 启示录\n    * JavaScript 语言精粹\n  ```\n\n<!-- more -->\n\n## nodejs 相关进阶\n  nodejs 底层理解, nodejs 加载 C/C++ addon, 全栈\n  ```\n    * nodejs 权威指南\n    * web 全栈工程师的自我修养\n    * C Primer Plus(第五版)\n    * C++ Primer中文版\n  ```\n\n## 架构设计&软件工程相关\n  web 架构设计, 软件工程管理\n  ```\n    * 人月神话\n    * 程序之美系列(架构之美, 安全之美, 数据之美)\n    * 大型网站技术架构: 核心原理与案例分析\n  ```\n\n## 七周系列\n  七周相关经典\n  ```\n    * 七周七语言\n    * 七周七并发模型\n    * 七周七数据库\n    * 七周七 web 开发框架\n  ```\n","tags":["读书"]}]